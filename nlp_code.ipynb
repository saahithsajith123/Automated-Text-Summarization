{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "id": "MXJMgvif6SkL",
        "outputId": "cbb27cc6-ba22-4a56-89c8-88a48c887297"
      },
      "outputs": [
        {
          "ename": "ParserError",
          "evalue": "Error tokenizing data. C error: EOF inside string starting at row 217285",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mParserError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-37-56a48b3ec479>\u001b[0m in \u001b[0;36m<cell line: 17>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;31m# Load the dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;31m# Display the first few rows of the dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-37-56a48b3ec479>\u001b[0m in \u001b[0;36mload_dataset\u001b[0;34m(file_path)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Load the dataset from a CSV file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mload_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;31m# For this example, assuming 'article' is the column containing the articles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m                     \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnew_arg_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_arg_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    329\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfind_stack_level\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m                 )\n\u001b[0;32m--> 331\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m         \u001b[0;31m# error: \"Callable[[VarArg(Any), KwArg(Any)], Any]\" has no\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    948\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 950\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    951\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    952\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    609\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    610\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 611\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    612\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    613\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1776\u001b[0m                     \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1777\u001b[0m                     \u001b[0mcol_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1778\u001b[0;31m                 \u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m  \u001b[0;31m# type: ignore[attr-defined]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1779\u001b[0m                     \u001b[0mnrows\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1780\u001b[0m                 )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/c_parser_wrapper.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m    228\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlow_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 230\u001b[0;31m                 \u001b[0mchunks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_low_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    231\u001b[0m                 \u001b[0;31m# destructive to chunks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_concatenate_chunks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.read_low_memory\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mParserError\u001b[0m: Error tokenizing data. C error: EOF inside string starting at row 217285"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the dataset from a CSV file\n",
        "def load_dataset(file_path):\n",
        "    dataset = pd.read_csv(file_path)\n",
        "\n",
        "    # For this example, assuming 'article' is the column containing the articles\n",
        "    # Adjust this based on the actual column names in your dataset\n",
        "    dataset = dataset.rename(columns={\"article\": \"text\"})\n",
        "\n",
        "    return dataset\n",
        "\n",
        "# Specify the file path for your dataset\n",
        "file_path = \"/content/train.csv\"\n",
        "\n",
        "# Load the dataset\n",
        "dataset = load_dataset(file_path)\n",
        "\n",
        "# Display the first few rows of the dataset\n",
        "print(dataset.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2lKmbCWMpWeD",
        "outputId": "9864d962-8d22-47b3-dd8b-75d4fd202a2a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                         id  \\\n",
            "0  92c514c913c0bdfe25341af9fd72b29db544099b   \n",
            "1  2003841c7dc0e7c5b1a248f9cd536d727f27a45a   \n",
            "2  91b7d2311527f5c2b63a65ca98d21d9c92485149   \n",
            "3  caabf9cbdf96eb1410295a673e953d304391bfbb   \n",
            "4  3da746a7d9afcaa659088c8366ef6347fe6b53ea   \n",
            "\n",
            "                                             article  \\\n",
            "0  Ever noticed how plane seats appear to be gett...   \n",
            "1  A drunk teenage boy had to be rescued by secur...   \n",
            "2  Dougie Freedman is on the verge of agreeing a ...   \n",
            "3  Liverpool target Neto is also wanted by PSG an...   \n",
            "4  Bruce Jenner will break his silence in a two-h...   \n",
            "\n",
            "                                          highlights  \n",
            "0  Experts question if  packed out planes are put...  \n",
            "1  Drunk teenage boy climbed into lion enclosure ...  \n",
            "2  Nottingham Forest are close to extending Dougi...  \n",
            "3  Fiorentina goalkeeper Neto has been linked wit...  \n",
            "4  Tell-all interview with the reality TV star, 6...  \n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "def load_dataset(file_path):\n",
        "    try:\n",
        "        # Try loading the dataset\n",
        "        dataset = pd.read_csv(file_path)\n",
        "        return dataset\n",
        "    except pd.errors.ParserError:\n",
        "        # If there's a parsing error, handle it\n",
        "        print(\"Parsing error encountered. Attempting to clean the data...\")\n",
        "        with open(file_path, 'r') as file:\n",
        "            lines = file.readlines()\n",
        "\n",
        "        # Clean the data (example: remove quotes)\n",
        "        cleaned_lines = [line.replace('\"', '') for line in lines]\n",
        "\n",
        "        # Write cleaned data to a temporary file\n",
        "        temp_file_path = 'temp.csv'\n",
        "        with open(temp_file_path, 'w') as temp_file:\n",
        "            temp_file.writelines(cleaned_lines)\n",
        "\n",
        "        # Load the cleaned dataset\n",
        "        dataset = pd.read_csv(temp_file_path)\n",
        "\n",
        "        # Remove temporary file\n",
        "        import os\n",
        "        os.remove(temp_file_path)\n",
        "\n",
        "        return dataset\n",
        "\n",
        "# Example usage:\n",
        "file_path = '/content/test.csv'\n",
        "dataset = load_dataset(file_path)\n",
        "print(dataset.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6f7XdkpzEh1R"
      },
      "outputs": [],
      "source": [
        "import csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sTd6r_yA7teQ",
        "outputId": "e6546e7c-1d84-41aa-8d02-57de20c04905"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import nltk\n",
        "import pandas as pd\n",
        "from nltk.tokenize import sent_tokenize, word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "import numpy as np\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JQqdKdR1E9Lq"
      },
      "outputs": [],
      "source": [
        "# Define the preprocess_text function\n",
        "def preprocess_text(text):\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    sentences = sent_tokenize(text)\n",
        "    preprocessed_sentences = []\n",
        "    for sent in sentences:\n",
        "        words = word_tokenize(sent)\n",
        "        words = [word.lower() for word in words if word.isalnum() and word.lower() not in stop_words]\n",
        "        preprocessed_sentences.append(\" \".join(words))\n",
        "    return preprocessed_sentences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b3RBN-d1EuO2"
      },
      "outputs": [],
      "source": [
        "# Apply TextRank algorithm for text summarization\n",
        "def textrank_summary(text, num_sentences=3):\n",
        "    preprocessed_sentences = preprocess_text(text)\n",
        "\n",
        "    sentence_similarity = np.zeros((len(preprocessed_sentences), len(preprocessed_sentences)))\n",
        "    for i in range(len(preprocessed_sentences)):\n",
        "        for j in range(len(preprocessed_sentences)):\n",
        "            if i != j:\n",
        "                sentence1 = set(preprocessed_sentences[i].split())\n",
        "                sentence2 = set(preprocessed_sentences[j].split())\n",
        "                similarity_score = len(sentence1.intersection(sentence2)) / (np.log(len(sentence1)) + np.log(len(sentence2)) + 1e-6)\n",
        "                sentence_similarity[i][j] = similarity_score\n",
        "\n",
        "    scores = np.ones(len(preprocessed_sentences))\n",
        "    damping_factor = 0.85\n",
        "    for _ in range(100):\n",
        "        new_scores = (1 - damping_factor) + damping_factor * np.sum(sentence_similarity, axis=1)\n",
        "        if np.allclose(new_scores, scores, rtol=1e-4):\n",
        "            break\n",
        "        scores = new_scores\n",
        "\n",
        "    top_sentences_idx = np.argsort(-scores)[:num_sentences]\n",
        "    summary = [preprocessed_sentences[i] for i in top_sentences_idx]\n",
        "\n",
        "    return \" \".join(summary)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        },
        "id": "x3nNVljeEz-w",
        "outputId": "7f10d833-7bea-40c4-8cc0-14eb4962073d"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'train' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-91ffed45bd82>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Apply TextRank summarization to the dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'text_column'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'article'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtextrank_summary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_sentences\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'dataset_with_summaries_text_rank.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Summaries saved to 'dataset_with_summaries_text_rank.csv'.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'train' is not defined"
          ]
        }
      ],
      "source": [
        "# Apply TextRank summarization to the dataset\n",
        "train['text_column'] = train['article'].apply(lambda x: textrank_summary(x, num_sentences=3))\n",
        "train.to_csv('dataset_with_summaries_text_rank.csv', index=False)\n",
        "print(\"Summaries saved to 'dataset_with_summaries_text_rank.csv'.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aa1gLEtVFO-O"
      },
      "outputs": [],
      "source": [
        "# Ensure 'article' column is string-like by converting to string\n",
        "dataset['article'] = dataset['article'].astype(str)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3Ns_30uyFLI7"
      },
      "outputs": [],
      "source": [
        "# Define the preprocess_text function\n",
        "def preprocess_text(text):\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    sentences = sent_tokenize(text)\n",
        "    preprocessed_sentences = []\n",
        "    for sent in sentences:\n",
        "        words = word_tokenize(sent)\n",
        "        words = [word.lower() for word in words if word.isalnum() and word.lower() not in stop_words]\n",
        "        preprocessed_sentences.append(\" \".join(words))\n",
        "    return preprocessed_sentences\n",
        "\n",
        "# Apply TextRank algorithm for text summarization\n",
        "def textrank_summary(text, num_sentences=3):\n",
        "    preprocessed_sentences = preprocess_text(text)\n",
        "\n",
        "    sentence_similarity = np.zeros((len(preprocessed_sentences), len(preprocessed_sentences)))\n",
        "    for i in range(len(preprocessed_sentences)):\n",
        "        for j in range(len(preprocessed_sentences)):\n",
        "            if i != j:\n",
        "                sentence1 = set(preprocessed_sentences[i].split())\n",
        "                sentence2 = set(preprocessed_sentences[j].split())\n",
        "                similarity_score = len(sentence1.intersection(sentence2)) / (np.log(len(sentence1)) + np.log(len(sentence2)) + 1e-6)\n",
        "                sentence_similarity[i][j] = similarity_score\n",
        "\n",
        "    scores = np.ones(len(preprocessed_sentences))\n",
        "    damping_factor = 0.85\n",
        "    for _ in range(100):\n",
        "        new_scores = (1 - damping_factor) + damping_factor * np.sum(sentence_similarity, axis=1)\n",
        "        if np.allclose(new_scores, scores, rtol=1e-4):\n",
        "            break\n",
        "        scores = new_scores\n",
        "\n",
        "    top_sentences_idx = np.argsort(-scores)[:num_sentences]\n",
        "    summary = [preprocessed_sentences[i] for i in top_sentences_idx]\n",
        "\n",
        "    return \" \".join(summary)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M5S7Fp3oFThS"
      },
      "outputs": [],
      "source": [
        "# Apply TextRank summarization to the dataset\n",
        "dataset['text_column'] = dataset['article'].apply(lambda x: textrank_summary(x, num_sentences=3))\n",
        "train.to_csv('dataset_with_summaries_text_rank.csv', index=False)\n",
        "print(\"Summaries saved to 'dataset_with_summaries_text_rank.csv'.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Watt_r7VQ0op"
      },
      "outputs": [],
      "source": [
        "# Apply TextRank summarization to the dataset\n",
        "dataset['text_column'] = dataset['article'].apply(lambda x: textrank_summary(x, num_sentences=3))\n",
        "dataset.to_csv('dataset_with_summaries_text_rank.csv', index=False)\n",
        "print(\"Summaries saved to 'dataset_with_summaries_text_rank.csv'.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4gxubS-XFkkQ"
      },
      "outputs": [],
      "source": [
        "# Display the first few rows of the dataset with summaries\n",
        "print(train.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YyGpWIeTrd_A"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import nltk\n",
        "import re\n",
        "from nltk.tokenize import sent_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import networkx as nx\n",
        "\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "# Function to load the dataset with error handling\n",
        "def load_dataset(file_path):\n",
        "    try:\n",
        "        dataset = pd.read_csv(file_path, error_bad_lines=False)  # Skip problematic rows\n",
        "    except pd.errors.ParserError as e:\n",
        "        print(f\"Error while parsing CSV: {e}\")\n",
        "        # Handle the error as needed, e.g., skip the row or display an error message\n",
        "        dataset = pd.DataFrame()  # Or provide an empty DataFrame\n",
        "\n",
        "    return dataset\n",
        "\n",
        "# Specify the file path for your dataset\n",
        "file_path = \"test.csv\"\n",
        "\n",
        "# Load the dataset with error handling\n",
        "dataset = load_dataset(file_path)\n",
        "\n",
        "if not dataset.empty:\n",
        "    # Data processing steps go here\n",
        "    print(dataset.head())\n",
        "\n",
        "# Data Preprocessing\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "# Function to clean text\n",
        "def clean_text(text):\n",
        "    text = re.sub(r'\\([^)]*\\)', '', text)\n",
        "    text = re.sub('\"', '', text)\n",
        "    text = ' '.join([word for word in text.split() if word.lower() not in stop_words])\n",
        "    return text\n",
        "\n",
        "df_cnn['cleaned_article'] = df_cnn['article'].apply(clean_text)\n",
        "\n",
        "# Tokenization\n",
        "def tokenize_sentences(article):\n",
        "    sentences = sent_tokenize(article)\n",
        "    return sentences\n",
        "\n",
        "# Function to generate article summary\n",
        "def generate_summary(article, n=5):\n",
        "    sentences = tokenize_sentences(article)\n",
        "    vectorizer = TfidfVectorizer()\n",
        "    X = vectorizer.fit_transform(sentences)\n",
        "    similarity_matrix = cosine_similarity(X, X)\n",
        "    nx_graph = nx.from_numpy_array(similarity_matrix)\n",
        "    scores = nx.pagerank(nx_graph)\n",
        "    ranked_sentences = sorted(((scores[i], sentence) for i, sentence in enumerate(sentences)), reverse=True)\n",
        "    summary_sentences = [sentence for _, sentence in ranked_sentences[:n]]\n",
        "    return ' '.join(summary_sentences)\n",
        "\n",
        "# Function to get the article and its summary based on ID\n",
        "def get_summary_by_id(dataframe, id):\n",
        "    row = dataframe[dataframe['id'] == id]\n",
        "    if not row.empty:\n",
        "        article = row['article'].values[0]\n",
        "        summary = generate_summary(article)\n",
        "        return article, summary\n",
        "    else:\n",
        "        return \"ID not found in the dataset\", \"\"\n",
        "\n",
        "# Example usage\n",
        "article_id = '0054d6d30dbcad772e20b22771153a2a9cbeaf62'\n",
        "article, summary = get_summary_by_id(df_cnn, article_id)\n",
        "print(\"Article:\\n\", article)\n",
        "print(\"\\nSummary:\\n\", summary)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bSnPf5nHQl8y"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import nltk\n",
        "import re\n",
        "from nltk.tokenize import sent_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import networkx as nx\n",
        "\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "\n",
        "# Function to load the dataset with error handling\n",
        "def load_dataset(file_path):\n",
        "    try:\n",
        "        dataset = pd.read_csv(file_path, error_bad_lines=False)  # Skip problematic rows\n",
        "    except pd.errors.ParserError as e:\n",
        "        print(f\"Error while parsing CSV: {e}\")\n",
        "        # Handle the error as needed, e.g., skip the row or display an error message\n",
        "        dataset = pd.DataFrame()  # Or provide an empty DataFrame\n",
        "\n",
        "    return dataset\n",
        "\n",
        "# Specify the file path for your dataset\n",
        "file_path = \"test.csv\"\n",
        "\n",
        "# Load the dataset with error handling\n",
        "dataset = load_dataset(file_path)\n",
        "\n",
        "if not dataset.empty:\n",
        "    # Data preprocessing: Cleaning the article text\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "\n",
        "    # Function to clean text\n",
        "    def clean_text(text):\n",
        "        text = re.sub(r'\\([^)]*\\)', '', text)\n",
        "        text = re.sub('\"', '', text)\n",
        "        text = ' '.join([word for word in text.split() if word.lower() not in stop_words])\n",
        "        return text\n",
        "\n",
        "    dataset['cleaned_article'] = dataset['article'].apply(clean_text)\n",
        "\n",
        "    # Tokenization\n",
        "    def tokenize_sentences(article):\n",
        "        sentences = sent_tokenize(article)\n",
        "        return sentences\n",
        "\n",
        "    # Function to generate article summary\n",
        "    def generate_summary(article, n=5):\n",
        "        sentences = tokenize_sentences(article)\n",
        "        vectorizer = TfidfVectorizer()\n",
        "        X = vectorizer.fit_transform(sentences)\n",
        "        similarity_matrix = cosine_similarity(X, X)\n",
        "        nx_graph = nx.from_numpy_array(similarity_matrix)\n",
        "        scores = nx.pagerank(nx_graph)\n",
        "        ranked_sentences = sorted(((scores[i], sentence) for i, sentence in enumerate(sentences)), reverse=True)\n",
        "        summary_sentences = [sentence for _, sentence in ranked_sentences[:n]]\n",
        "        return ' '.join(summary_sentences)\n",
        "\n",
        "    # Function to get the article and its summary based on ID\n",
        "    def get_summary_by_id(dataframe, id):\n",
        "        row = dataframe[dataframe['id'] == id]\n",
        "        if not row.empty:\n",
        "            article = row['article'].values[0]\n",
        "            summary = generate_summary(article)\n",
        "            return article, summary\n",
        "        else:\n",
        "            return \"ID not found in the dataset\", \"\"\n",
        "\n",
        "    # Example usage\n",
        "    article_id = '0054d6d30dbcad772e20b22771153a2a9cbeaf62'\n",
        "    article, summary = get_summary_by_id(dataset, article_id)\n",
        "    print(\"Article:\\n\", article)\n",
        "    print(\"\\nSummary:\\n\", summary)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "injylPThQ75I"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import nltk\n",
        "import re\n",
        "from nltk.tokenize import sent_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import networkx as nx\n",
        "\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "\n",
        "# Function to load the dataset with error handling\n",
        "def load_dataset(file_path):\n",
        "    try:\n",
        "        dataset = pd.read_csv(file_path, error_bad_lines=False, skiprows=range(10863, None))  # Skip problematic rows\n",
        "    except pd.errors.ParserError as e:\n",
        "        print(f\"Error while parsing CSV: {e}\")\n",
        "        # Handle the error as needed, e.g., skip the row or display an error message\n",
        "        dataset = pd.DataFrame()  # Or provide an empty DataFrame\n",
        "\n",
        "    return dataset\n",
        "\n",
        "# Specify the file path for your dataset\n",
        "file_path = \"test.csv\"\n",
        "\n",
        "# Load the dataset with error handling\n",
        "dataset = load_dataset(file_path)\n",
        "\n",
        "if not dataset.empty:\n",
        "    # Data preprocessing: Cleaning the article text\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "\n",
        "    # Function to clean text\n",
        "    def clean_text(text):\n",
        "        text = re.sub(r'\\([^)]*\\)', '', text)\n",
        "        text = re.sub('\"', '', text)\n",
        "        text = ' '.join([word for word in text.split() if word.lower() not in stop_words])\n",
        "        return text\n",
        "\n",
        "    dataset['cleaned_article'] = dataset['article'].apply(clean_text)\n",
        "\n",
        "    # Tokenization\n",
        "    def tokenize_sentences(article):\n",
        "        sentences = sent_tokenize(article)\n",
        "        return sentences\n",
        "\n",
        "    # Function to generate article summary\n",
        "    def generate_summary(article, n=5):\n",
        "        sentences = tokenize_sentences(article)\n",
        "        vectorizer = TfidfVectorizer()\n",
        "        X = vectorizer.fit_transform(sentences)\n",
        "        similarity_matrix = cosine_similarity(X, X)\n",
        "        nx_graph = nx.from_numpy_array(similarity_matrix)\n",
        "        scores = nx.pagerank(nx_graph)\n",
        "        ranked_sentences = sorted(((scores[i], sentence) for i, sentence in enumerate(sentences)), reverse=True)\n",
        "        summary_sentences = [sentence for _, sentence in ranked_sentences[:n]]\n",
        "        return ' '.join(summary_sentences)\n",
        "\n",
        "    # Function to get the article and its summary based on ID\n",
        "    def get_summary_by_id(dataframe, id):\n",
        "        row = dataframe[dataframe['id'] == id]\n",
        "        if not row.empty:\n",
        "            article = row['article'].values[0]\n",
        "            summary = generate_summary(article)\n",
        "            return article, summary\n",
        "        else:\n",
        "            return \"ID not found in the dataset\", \"\"\n",
        "\n",
        "    # Example usage\n",
        "    article_id = '0054d6d30dbcad772e20b22771153a2a9cbeaf62'\n",
        "    article, summary = get_summary_by_id(dataset, article_id)\n",
        "    print(\"Article:\\n\", article)\n",
        "    print(\"\\nSummary:\\n\", summary)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JfhSTlnORlUe"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import nltk\n",
        "import re\n",
        "from nltk.tokenize import sent_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import networkx as nx\n",
        "\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "\n",
        "# Function to load the dataset with error handling\n",
        "def load_dataset(file_path):\n",
        "    try:\n",
        "        dataset = pd.read_csv(file_path, error_bad_lines=False, skiprows=lambda x: x >= 10863)  # Skip rows starting from 10863\n",
        "    except pd.errors.ParserError as e:\n",
        "        print(f\"Error while parsing CSV: {e}\")\n",
        "        # Handle the error as needed, e.g., skip the row or display an error message\n",
        "        dataset = pd.DataFrame()  # Or provide an empty DataFrame\n",
        "\n",
        "    return dataset\n",
        "\n",
        "# Specify the file path for your dataset\n",
        "file_path = \"test.csv\"\n",
        "\n",
        "# Load the dataset with error handling\n",
        "dataset = load_dataset(file_path)\n",
        "\n",
        "if not dataset.empty:\n",
        "    # Data preprocessing: Cleaning the article text\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "\n",
        "    # Function to clean text\n",
        "    def clean_text(text):\n",
        "        text = re.sub(r'\\([^)]*\\)', '', text)\n",
        "        text = re.sub('\"', '', text)\n",
        "        text = ' '.join([word for word in text.split() if word.lower() not in stop_words])\n",
        "        return text\n",
        "\n",
        "    dataset['cleaned_article'] = dataset['article'].apply(clean_text)\n",
        "\n",
        "    # Tokenization\n",
        "    def tokenize_sentences(article):\n",
        "        sentences = sent_tokenize(article)\n",
        "        return sentences\n",
        "\n",
        "    # Function to generate article summary\n",
        "    def generate_summary(article, n=5):\n",
        "        sentences = tokenize_sentences(article)\n",
        "        vectorizer = TfidfVectorizer()\n",
        "        X = vectorizer.fit_transform(sentences)\n",
        "        similarity_matrix = cosine_similarity(X, X)\n",
        "        nx_graph = nx.from_numpy_array(similarity_matrix)\n",
        "        scores = nx.pagerank(nx_graph)\n",
        "        ranked_sentences = sorted(((scores[i], sentence) for i, sentence in enumerate(sentences)), reverse=True)\n",
        "        summary_sentences = [sentence for _, sentence in ranked_sentences[:n]]\n",
        "        return ' '.join(summary_sentences)\n",
        "\n",
        "    # Function to get the article and its summary based on ID\n",
        "    def get_summary_by_id(dataframe, id):\n",
        "        row = dataframe[dataframe['id'] == id]\n",
        "        if not row.empty:\n",
        "            article = row['article'].values[0]\n",
        "            summary = generate_summary(article)\n",
        "            return article, summary\n",
        "        else:\n",
        "            return \"ID not found in the dataset\", \"\"\n",
        "\n",
        "    # Example usage\n",
        "if not dataset.empty:\n",
        "    article_id = '92c514c913c0bdfe25341af9fd72b29db544099b'\n",
        "    article, summary = get_summary_by_id(dataset, article_id)\n",
        "\n",
        "    # Counting words in the article and summary\n",
        "    article_word_count = count_words(article)\n",
        "    summary_word_count = count_words(summary)\n",
        "\n",
        "    print(\"Article Word Count:\", article_word_count)\n",
        "    print(\"Summary Word Count:\", summary_word_count)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OJtIQx57TLGE"
      },
      "outputs": [],
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9ETQjA2QXDUz"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import networkx as nx\n",
        "from nltk.tokenize import sent_tokenize\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "import re\n",
        "from string import punctuation\n",
        "from heapq import nlargest\n",
        "\n",
        "# Load the dataset\n",
        "df = pd.read_csv(\"test.csv\")\n",
        "\n",
        "# Contractions dictionary and regex\n",
        "contractions_dict = {\n",
        "    \"ain't\": \"am not\",\n",
        "    \"aren't\": \"are not\",\n",
        "    \"can't\": \"cannot\",\n",
        "    \"can't've\": \"cannot have\",\n",
        "    \"'cause\": \"because\",\n",
        "    \"could've\": \"could have\",\n",
        "    \"couldn't\": \"could not\",\n",
        "    \"couldn't've\": \"could not have\",\n",
        "    \"didn't\": \"did not\",\n",
        "    \"doesn't\": \"does not\",\n",
        "    \"don't\": \"do not\",\n",
        "    \"hadn't\": \"had not\",\n",
        "    \"hadn't've\": \"had not have\",\n",
        "    \"hasn't\": \"has not\",\n",
        "    \"haven't\": \"have not\",\n",
        "    \"he'd\": \"he had\",\n",
        "    \"he'd've\": \"he would have\",\n",
        "    \"he'll\": \"he will\",\n",
        "    \"he'll've\": \"he will have\",\n",
        "    \"he's\": \"he is\",\n",
        "    \"how'd\": \"how did\",\n",
        "    \"how'd'y\": \"how do you\",\n",
        "    \"how'll\": \"how will\",\n",
        "    \"how's\": \"how is\",\n",
        "    \"i'd\": \"i would\",\n",
        "    \"i'd've\": \"i would have\",\n",
        "    \"i'll\": \"i will\",\n",
        "    \"i'll've\": \"i will have\",\n",
        "    \"i'm\": \"i am\",\n",
        "    \"i've\": \"i have\",\n",
        "    \"isn't\": \"is not\",\n",
        "    \"it'd\": \"it would\",\n",
        "    \"it'd've\": \"it would have\",\n",
        "    \"it'll\": \"it will\",\n",
        "    \"it'll've\": \"it will have\",\n",
        "    \"it's\": \"it is\",\n",
        "    \"let's\": \"let us\",\n",
        "    \"ma'am\": \"madam\",\n",
        "    \"mayn't\": \"may not\",\n",
        "    \"might've\": \"might have\",\n",
        "    \"mightn't\": \"might not\",\n",
        "    \"mightn't've\": \"might not have\",\n",
        "    \"must've\": \"must have\",\n",
        "    \"mustn't\": \"must not\",\n",
        "    \"mustn't've\": \"must not have\",\n",
        "    \"needn't\": \"need not\",\n",
        "    \"needn't've\": \"need not have\",\n",
        "    \"o'clock\": \"of the clock\",\n",
        "    \"oughtn't\": \"ought not\",\n",
        "    \"oughtn't've\": \"ought not have\",\n",
        "    \"shan't\": \"shall not\",\n",
        "    \"sha'n't\": \"shall not\",\n",
        "    \"shan't've\": \"shall not have\",\n",
        "    \"she'd\": \"she would\",\n",
        "    \"she'd've\": \"she would have\",\n",
        "    \"she'll\": \"she will\",\n",
        "    \"she'll've\": \"she will have\",\n",
        "    \"she's\": \"she is\",\n",
        "    \"should've\": \"should have\",\n",
        "    \"shouldn't\": \"should not\",\n",
        "    \"shouldn't've\": \"should not have\",\n",
        "    \"so've\": \"so have\",\n",
        "    \"so's\": \"so is\",\n",
        "    \"that'd\": \"that would\",\n",
        "    \"that'd've\": \"that would have\",\n",
        "    \"that's\": \"that is\",\n",
        "    \"there'd\": \"there would\",\n",
        "    \"there'd've\": \"there would have\",\n",
        "    \"there's\": \"there is\",\n",
        "    \"they'd\": \"they would\",\n",
        "    \"they'd've\": \"they would have\",\n",
        "    \"they'll\": \"they will\",\n",
        "    \"they'll've\": \"they will have\",\n",
        "    \"they're\": \"they are\",\n",
        "    \"they've\": \"they have\",\n",
        "    \"to've\": \"to have\",\n",
        "    \"wasn't\": \"was not\",\n",
        "    \"we'd\": \"we would\",\n",
        "    \"we'd've\": \"we would have\",\n",
        "    \"we'll\": \"we will\",\n",
        "    \"we'll've\": \"we will have\",\n",
        "    \"we're\": \"we are\",\n",
        "    \"we've\": \"we have\",\n",
        "    \"weren't\": \"were not\",\n",
        "    \"what'll\": \"what will\",\n",
        "    \"what'll've\": \"what will have\",\n",
        "    \"what're\": \"what are\",\n",
        "    \"what's\": \"what is\",\n",
        "    \"what've\": \"what have\",\n",
        "    \"when's\": \"when is\",\n",
        "    \"when've\": \"when have\",\n",
        "    \"where'd\": \"where did\",\n",
        "    \"where's\": \"where is\",\n",
        "    \"where've\": \"where have\",\n",
        "    \"who'll\": \"who will\",\n",
        "    \"who'll've\": \"who will have\",\n",
        "    \"who's\": \"who is\",\n",
        "    \"who've\": \"who have\",\n",
        "    \"why's\": \"why is\",\n",
        "    \"why've\": \"why have\",\n",
        "    \"will've\": \"will have\",\n",
        "    \"won't\": \"will not\",\n",
        "    \"won't've\": \"will not have\",\n",
        "    \"would've\": \"would have\",\n",
        "    \"wouldn't\": \"would not\",\n",
        "    \"wouldn't've\": \"would not have\",\n",
        "    \"y'all\": \"you all\",\n",
        "    \"yâ€™all\": \"you all\",\n",
        "    \"y'all'd\": \"you all would\",\n",
        "    \"y'all'd've\": \"you all would have\",\n",
        "    \"y'all're\": \"you all are\",\n",
        "    \"y'all've\": \"you all have\",\n",
        "    \"you'd\": \"you would\",\n",
        "    \"you'd've\": \"you would have\",\n",
        "    \"you'll\": \"you will\",\n",
        "    \"you'll've\": \"you will have\",\n",
        "    \"you're\": \"you are\",\n",
        "    \"you're\": \"you are\",\n",
        "    \"you've\": \"you have\",\n",
        "}\n",
        "\n",
        "contractions_re = re.compile('(%s)' % '|'.join(contractions_dict.keys()))\n",
        "\n",
        "# Function to clean the HTML from the article"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K8MruaFuXKZJ"
      },
      "outputs": [],
      "source": [
        "# Function to clean HTML tags from the article\n",
        "def clean_html(raw_html):\n",
        "    cleanr = re.compile('<.*?>')\n",
        "    cleantext = re.sub(cleanr, '', raw_html)\n",
        "    return cleantext\n",
        "\n",
        "# Function to expand contractions\n",
        "def expand_contractions(s, contractions_dict=contractions_dict):\n",
        "    def replace(match):\n",
        "        return contractions_dict[match.group(0)]\n",
        "    return contractions_re.sub(replace, s)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aDSiwVTJXW3S"
      },
      "outputs": [],
      "source": [
        "# Preprocessing function\n",
        "def preprocess_text(text):\n",
        "    text = text.lower()  # Convert to lowercase\n",
        "    text = clean_html(text)  # Remove HTML tags\n",
        "    text = expand_contractions(text)  # Expand contractions\n",
        "    text = re.sub(r'\\S+@\\S+', '', text)  # Remove email addresses\n",
        "    text = re.sub(r\"http\\S+|www\\S+|https\\S+\", \"\", text, flags=re.MULTILINE)  # Remove URLs\n",
        "    text = text.replace(\"\\xa0\", \" \")  # Remove '\\xa0'\n",
        "    text = text.replace(\"'s\", '')  # Strip possessives\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()  # Remove extra whitespaces\n",
        "    return text\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r_bPvKCrXYQ4"
      },
      "outputs": [],
      "source": [
        "# Function to preprocess the entire article\n",
        "def preprocess_article(article):\n",
        "    return preprocess_text(article)\n",
        "\n",
        "# Function to preprocess the article and tokenize it into sentences\n",
        "def preprocess_and_tokenize(article):\n",
        "    sentences = sent_tokenize(preprocess_article(article))\n",
        "    return sentences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iYYHRE0hXdVV"
      },
      "outputs": [],
      "source": [
        "# Function to create a graph from sentences\n",
        "def create_graph(sentences):\n",
        "    graph = nx.Graph()\n",
        "    graph.add_nodes_from(range(len(sentences)))\n",
        "    vectorizer = CountVectorizer().fit_transform(sentences)\n",
        "    similarity_matrix = cosine_similarity(vectorizer)\n",
        "    for i in range(len(sentences)):\n",
        "        for j in range(i+1, len(sentences)):\n",
        "            graph.add_edge(i, j, weight=similarity_matrix[i][j])\n",
        "    return graph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yD47U0QwXhSL",
        "outputId": "cd88f1cb-a12b-4f5a-ca9b-f306b2612bd0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Article:\n",
            " Ever noticed how plane seats appear to be getting smaller and smaller? With increasing numbers of people taking to the skies, some experts are questioning if having such packed out planes is putting passengers at risk. They say that the shrinking space on aeroplanes is not only uncomfortable - it's putting our health and safety in danger. More than squabbling over the arm rest, shrinking space on planes putting our health and safety in danger? This week, a U.S consumer advisory group set up by the Department of Transportation said at a public hearing that while the government is happy to set standards for animals flying on planes, it doesn't stipulate a minimum amount of space for humans. 'In a world where animals have more rights to space and food than humans,' said Charlie Leocha, consumer representative on the committee.Â 'It is time that the DOT and FAA take a stand for humane treatment of passengers.' But could crowding on planes lead to more serious issues than fighting for space in the overhead lockers, crashing elbows and seat back kicking? Tests conducted by the FAA use planes with a 31 inch pitch, a standard which on some airlines has decreased . Many economy seats on United Airlines have 30 inches of room, while some airlines offer as little as 28 inches . Cynthia Corbertt, a human factors researcher with the Federal Aviation Administration, that it conducts tests on how quickly passengers can leave a plane. But these tests are conducted using planes with 31 inches between each row of seats, a standard which on some airlines has decreased, reported the Detroit News. The distance between two seats from one point on a seat to the same point on the seat behind it is known as the pitch. While most airlines stick to a pitch of 31 inches or above, some fall below this. While United Airlines has 30 inches of space, Gulf Air economy seats have between 29 and 32 inches, Air Asia offers 29 inches and Spirit Airlines offers just 28 inches. British Airways has a seat pitch of 31 inches, while easyJet has 29 inches, Thomson's short haul seat pitch is 28 inches, and Virgin Atlantic's is 30-31.\n",
            "\n",
            "Summary:\n",
            " but these tests are conducted using planes with 31 inches between each row of seats, a standard which on some airlines has decreased, reported the detroit news. the distance between two seats from one point on a seat to the same point on the seat behind it is known as the pitch. this week, a u.s consumer advisory group set up by the department of transportation said at a public hearing that while the government is happy to set standards for animals flying on planes, it does not stipulate a minimum amount of space for humans.\n",
            "\n",
            "Number of words in article: 370\n",
            "Number of words in summary: 96\n"
          ]
        }
      ],
      "source": [
        "# Function to rank sentences using TextRank algorithm\n",
        "def text_rank(graph):\n",
        "    scores = nx.pagerank(graph)\n",
        "    return scores\n",
        "\n",
        "# Function to generate summary\n",
        "def generate_summary(article, scores, top_n=3):\n",
        "    ranked_sentences = sorted(((scores[i], s) for i, s in enumerate(article)), reverse=True)\n",
        "    summary = ' '.join([sentence[1] for sentence in ranked_sentences[:top_n]])\n",
        "    return summary\n",
        "\n",
        "# Main function\n",
        "def main(article_id):\n",
        "    # Get article based on article_id\n",
        "    article = df.loc[df['id'] == article_id]['article'].values[0]\n",
        "\n",
        "    # Preprocess the article and tokenize into sentences\n",
        "    preprocessed_sentences = preprocess_and_tokenize(article)\n",
        "\n",
        "    # Create graph from sentences\n",
        "    graph = create_graph(preprocessed_sentences)\n",
        "\n",
        "    # Rank sentences using TextRank algorithm\n",
        "    scores = text_rank(graph)\n",
        "\n",
        "    # Generate summary\n",
        "    summary = generate_summary(preprocessed_sentences, scores)\n",
        "\n",
        "    # Return article and summary\n",
        "    return article, summary\n",
        "\n",
        "# Test the function\n",
        "article_id = '92c514c913c0bdfe25341af9fd72b29db544099b'  # Example ID\n",
        "article, summary = main(article_id)\n",
        "\n",
        "# Count the number of words in article and summary\n",
        "article_word_count = len(article.split())\n",
        "summary_word_count = len(summary.split())\n",
        "\n",
        "print(\"Article:\\n\", article)\n",
        "print(\"\\nSummary:\\n\", summary)\n",
        "print(\"\\nNumber of words in article:\", article_word_count)\n",
        "print(\"Number of words in summary:\", summary_word_count)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0YIbp3_DYUbd",
        "outputId": "dd9c3b06-ff61-4b91-8444-922b013ae16e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting rouge\n",
            "  Downloading rouge-1.0.1-py3-none-any.whl (13 kB)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from rouge) (1.16.0)\n",
            "Installing collected packages: rouge\n",
            "Successfully installed rouge-1.0.1\n"
          ]
        }
      ],
      "source": [
        "pip install rouge\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IS-puAfxYZ7u",
        "outputId": "d04922e3-0108-4081-9996-86e016fa0a53"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ROUGE scores:\n",
            "[{'rouge-1': {'r': 0.3939393939393939, 'p': 0.17567567567567569, 'f': 0.2429906499397328}, 'rouge-2': {'r': 0.09090909090909091, 'p': 0.031578947368421054, 'f': 0.04687499617309602}, 'rouge-l': {'r': 0.3939393939393939, 'p': 0.17567567567567569, 'f': 0.2429906499397328}}]\n"
          ]
        }
      ],
      "source": [
        "from rouge import Rouge\n",
        "\n",
        "# Function to calculate ROUGE scores\n",
        "def calculate_rouge(reference_summary, generated_summary):\n",
        "    rouge = Rouge()\n",
        "    scores = rouge.get_scores(generated_summary, reference_summary)\n",
        "    return scores\n",
        "\n",
        "# Reference summary (highlight) from the dataset\n",
        "reference_summary = df.loc[df['id'] == article_id]['highlights'].values[0]\n",
        "\n",
        "# Calculate ROUGE scores\n",
        "rouge_scores = calculate_rouge(reference_summary, summary)\n",
        "\n",
        "# Print ROUGE scores\n",
        "print(\"ROUGE scores:\")\n",
        "print(rouge_scores)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rTLDMlGxpzmc"
      },
      "outputs": [],
      "source": [
        "import textwrap\n",
        "from transformers import pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k3hIQjf3Y97Z",
        "outputId": "ec8bcdd7-83e5-4054-8cf5-fd06b62778de"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Article:\n",
            " Ever noticed how plane seats appear to be getting smaller and smaller? With increasing numbers of people taking to the skies, some experts are questioning if having such packed out planes is putting passengers at risk. They say that the shrinking space on aeroplanes is not only uncomfortable - it's putting our health and safety in danger. More than squabbling over the arm rest, shrinking space on planes putting our health and safety in danger? This week, a U.S consumer advisory group set up by the Department of Transportation said at a public hearing that while the government is happy to set standards for animals flying on planes, it doesn't stipulate a minimum amount of space for humans. 'In a world where animals have more rights to space and food than humans,' said Charlie Leocha, consumer representative on the committee.Â 'It is time that the DOT and FAA take a stand for humane treatment of passengers.' But could crowding on planes lead to more serious issues than fighting for space in the overhead lockers, crashing elbows and seat back kicking? Tests conducted by the FAA use planes with a 31 inch pitch, a standard which on some airlines has decreased . Many economy seats on United Airlines have 30 inches of room, while some airlines offer as little as 28 inches . Cynthia Corbertt, a human factors researcher with the Federal Aviation Administration, that it conducts tests on how quickly passengers can leave a plane. But these tests are conducted using planes with 31 inches between each row of seats, a standard which on some airlines has decreased, reported the Detroit News. The distance between two seats from one point on a seat to the same point on the seat behind it is known as the pitch. While most airlines stick to a pitch of 31 inches or above, some fall below this. While United Airlines has 30 inches of space, Gulf Air economy seats have between 29 and 32 inches, Air Asia offers 29 inches and Spirit Airlines offers just 28 inches. British Airways has a seat pitch of 31 inches, while easyJet has 29 inches, Thomson's short haul seat pitch is 28 inches, and Virgin Atlantic's is 30-31.\n",
            "\n",
            "Summary:\n",
            " but these tests are conducted using planes with 31 inches between each row of seats, a standard which on some airlines has decreased, reported the detroit news. the distance between two seats from one point on a seat to the same point on the seat behind it is known as the pitch. this week, a u.s consumer advisory group set up by the department of transportation said at a public hearing that while the government is happy to set standards for animals flying on planes, it does not stipulate a minimum amount of space for humans.\n",
            "\n",
            "Number of words in article: 370\n",
            "Number of words in summary: 96\n",
            "Article:\n",
            " Ever noticed how plane seats appear to be getting smaller and smaller? With\n",
            "increasing numbers of people taking to the skies, some experts are questioning\n",
            "if having such packed out planes is putting passengers at risk. They say that\n",
            "the shrinking space on aeroplanes is not only uncomfortable - it's putting our\n",
            "health and safety in danger. More than squabbling over the arm rest, shrinking\n",
            "space on planes putting our health and safety in danger? This week, a U.S\n",
            "consumer advisory group set up by the Department of Transportation said at a\n",
            "public hearing that while the government is happy to set standards for animals\n",
            "flying on planes, it doesn't stipulate a minimum amount of space for humans. 'In\n",
            "a world where animals have more rights to space and food than humans,' said\n",
            "Charlie Leocha, consumer representative on the committee.Â 'It is time that the\n",
            "DOT and FAA take a stand for humane treatment of passengers.' But could crowding\n",
            "on planes lead to more serious issues than fighting for space in the overhead\n",
            "lockers, crashing elbows and seat back kicking? Tests conducted by the FAA use\n",
            "planes with a 31 inch pitch, a standard which on some airlines has decreased .\n",
            "Many economy seats on United Airlines have 30 inches of room, while some\n",
            "airlines offer as little as 28 inches . Cynthia Corbertt, a human factors\n",
            "researcher with the Federal Aviation Administration, that it conducts tests on\n",
            "how quickly passengers can leave a plane. But these tests are conducted using\n",
            "planes with 31 inches between each row of seats, a standard which on some\n",
            "airlines has decreased, reported the Detroit News. The distance between two\n",
            "seats from one point on a seat to the same point on the seat behind it is known\n",
            "as the pitch. While most airlines stick to a pitch of 31 inches or above, some\n",
            "fall below this. While United Airlines has 30 inches of space, Gulf Air economy\n",
            "seats have between 29 and 32 inches, Air Asia offers 29 inches and Spirit\n",
            "Airlines offers just 28 inches. British Airways has a seat pitch of 31 inches,\n",
            "while easyJet has 29 inches, Thomson's short haul seat pitch is 28 inches, and\n",
            "Virgin Atlantic's is 30-31.\n",
            "\n",
            "Summary:\n",
            " but these tests are conducted using planes with 31 inches between each row of\n",
            "seats, a standard which on some airlines has decreased, reported the detroit\n",
            "news. the distance between two seats from one point on a seat to the same point\n",
            "on the seat behind it is known as the pitch. this week, a u.s consumer advisory\n",
            "group set up by the department of transportation said at a public hearing that\n",
            "while the government is happy to set standards for animals flying on planes, it\n",
            "does not stipulate a minimum amount of space for humans.\n",
            "ROUGE scores:\n",
            "[{'rouge-1': {'r': 0.3939393939393939, 'p': 0.17567567567567569, 'f': 0.2429906499397328}, 'rouge-2': {'r': 0.09090909090909091, 'p': 0.031578947368421054, 'f': 0.04687499617309602}, 'rouge-l': {'r': 0.3939393939393939, 'p': 0.17567567567567569, 'f': 0.2429906499397328}}]\n"
          ]
        }
      ],
      "source": [
        "# Test the function\n",
        "article_id = '92c514c913c0bdfe25341af9fd72b29db544099b'  # Example ID\n",
        "article, summary = main(article_id)\n",
        "\n",
        "# Count the number of words in article and summary\n",
        "article_word_count = len(article.split())\n",
        "summary_word_count = len(summary.split())\n",
        "\n",
        "print(\"Article:\\n\", article)\n",
        "print(\"\\nSummary:\\n\", summary)\n",
        "print(\"\\nNumber of words in article:\", article_word_count)\n",
        "print(\"Number of words in summary:\", summary_word_count)\n",
        "\n",
        "# Word wrap article and summary\n",
        "wrapper = textwrap.TextWrapper(width=80)\n",
        "article_wrapped = wrapper.fill(text=article)\n",
        "summary_wrapped = wrapper.fill(text=summary)\n",
        "\n",
        "# Print article, summary, and word counts\n",
        "print(\"Article:\\n\", article_wrapped)\n",
        "print(\"\\nSummary:\\n\", summary_wrapped)\n",
        "\n",
        "from rouge import Rouge\n",
        "\n",
        "# Function to calculate ROUGE scores\n",
        "def calculate_rouge(reference_summary, generated_summary):\n",
        "    rouge = Rouge()\n",
        "    scores = rouge.get_scores(generated_summary, reference_summary)\n",
        "    return scores\n",
        "\n",
        "# Reference summary (highlight) from the dataset\n",
        "reference_summary = df.loc[df['id'] == article_id]['highlights'].values[0]\n",
        "\n",
        "# Calculate ROUGE scores\n",
        "rouge_scores = calculate_rouge(reference_summary, summary)\n",
        "\n",
        "# Print ROUGE scores\n",
        "print(\"ROUGE scores:\")\n",
        "print(rouge_scores)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 388,
          "referenced_widgets": [
            "b62b98fc82fc4206b0b12c48ca5f0cb5",
            "8c9a9a66ce764e8784c381ed23b3a8a7",
            "6a53a39f48944be1a9438981a2997c56",
            "3231d6bafa5a43f8a2f86e3e6aa4a0fd",
            "1335deb08d524996b4f66836473c8f52",
            "a7834e638b8d498587e8fbd3375b3f41",
            "0466b74024004c05aca1ab4f61b077f5",
            "2d3935dc021c4dda9347bf1cebc57b62",
            "075a8d1e7cc848ac96cda9f6ca146529",
            "dcbc09b26b1847eaac54215b77fcb5c4",
            "06ea068b54d549eb954a942eb764748e",
            "1703b546d3954e63ac1a8161e19e7f81",
            "bd7c730edb574efeb00a3cd3db378fd9",
            "d2de7ffbe6a34268829b2e4f890e9537",
            "8cbba3cdb9d8438e872e243148f181a3",
            "d172034ce6914023bed2cfee54c52aad",
            "0890a6f7a7a342f5abfdd8e4f1d9eea6",
            "090fc670cebd4e858c3560e6cb1263e6",
            "e73d2dd712714f09b3d68fac3bc7ceb0",
            "57ac8bdfda904af19bd74e09214d7e8b",
            "ac03819eab614f1eb81587245b62e1d7",
            "f8c6844bdd1e482385737021500a4508",
            "cf04f57fcac64daa89df0cd43668f6ad",
            "ca895eb1ef254a76877adb28d5b37d50",
            "5a123fea44464a1a837ee5ce5d0e0bf6",
            "c6db81e5d6574ffb8613e51003077c73",
            "73724debb8024d80ae6dcefc3fb881de",
            "5c70383ce36c4bf0abe490f698ff1d4b",
            "4713d0cd52d24df2a57553a7acce03cf",
            "9b8ba72693774eeb8be28cbb831f2790",
            "86b8d9d8e55645218b1e1a19ba8fd494",
            "5d940137e45f42a5b15b0e96fe55462f",
            "12c028302e894a728e848409e4051fde",
            "2cf45b705ae84a3fa56f1ba62c4e2f99",
            "efe4c577478449f4805c9c58a0f34c0d",
            "e10a2e4aff3147f99dfa288add2469dd",
            "bde8c243711d45e2b8065582f20ce72f",
            "19e02c007fc247728fbb20085b217e13",
            "4e1571f445144bc19f163879434de4e8",
            "3899c929344d49929b40704c8685423a",
            "bf2f2bc6fa8b49709bd05c23d3fc0659",
            "fcf9bec909094cdfb2d59ae7a46f205e",
            "2da5f54840cf4a4aa3d19eade319cf67",
            "0433cb7e967a4e45960ac5a7af6ded73",
            "51f9c15d44674724a03774652a831627",
            "a653d99d42af4420af9581825b8d5a07",
            "85e9fee68f704c94b94e535090d86868",
            "2079401f23724393ad181d6c5c689dfa",
            "039fb807ac6b49269fdab8c32b607aa0",
            "aaec799a6984498c83999193f6d6aaa9",
            "5f8dc93910724537954edb8ad977ecef",
            "40ddf450b8694ba38c723553e82b7677",
            "8625b0947b834383b5618f6919829492",
            "98c458f661c940ca8bbe389b6712b204",
            "70803203a6eb412690b761113f836add"
          ]
        },
        "id": "Po-SJfUiZqwp",
        "outputId": "65f3e8ef-92bd-4921-d364-8b617d352c61"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "No model was supplied, defaulted to sshleifer/distilbart-cnn-12-6 and revision a4f8f3e (https://huggingface.co/sshleifer/distilbart-cnn-12-6).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b62b98fc82fc4206b0b12c48ca5f0cb5",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/1.80k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1703b546d3954e63ac1a8161e19e7f81",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "pytorch_model.bin:   0%|          | 0.00/1.22G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "cf04f57fcac64daa89df0cd43668f6ad",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2cf45b705ae84a3fa56f1ba62c4e2f99",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "51f9c15d44674724a03774652a831627",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "BERT-generated Summary:\n",
            "  U.S consumer advisory group set up by the Department of Transportation said that while the government is happy to set standards for animals flying on planes, it doesn't stipulate a minimum amount of space for humans . Many economy seats on United Airlines have 30 inches of room, while some airlines offer as little as 28 inches .\n"
          ]
        }
      ],
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "# Load the BERT-based text summarization pipeline\n",
        "summarization_pipeline = pipeline(\"summarization\")\n",
        "\n",
        "# Function to generate summary using BERT\n",
        "def generate_summary_bert(article):\n",
        "    summarized_text = summarization_pipeline(article, max_length=150, min_length=30, do_sample=False)\n",
        "    summary = summarized_text[0]['summary_text']\n",
        "    return summary\n",
        "\n",
        "# Main function with BERT summarization\n",
        "def main_bert(article_id):\n",
        "    # Get article based on article_id\n",
        "    article = df.loc[df['id'] == article_id]['article'].values[0]\n",
        "\n",
        "    # Generate summary using BERT\n",
        "    summary = generate_summary_bert(article)\n",
        "\n",
        "    # Return article and summary\n",
        "    return article, summary\n",
        "\n",
        "# Test the BERT-based summarization function\n",
        "article_id = '92c514c913c0bdfe25341af9fd72b29db544099b'  # Example ID\n",
        "article, summary_bert = main_bert(article_id)\n",
        "\n",
        "# Print the BERT-generated summary\n",
        "print(\"\\nBERT-generated Summary:\\n\", summary_bert)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DECqLhsfaPox",
        "outputId": "e13e739c-23ae-40d9-afef-bbc8ac12d463"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "No model was supplied, defaulted to sshleifer/distilbart-cnn-12-6 and revision a4f8f3e (https://huggingface.co/sshleifer/distilbart-cnn-12-6).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Article:\n",
            " Ever noticed how plane seats appear to be getting smaller and smaller? With increasing numbers of people taking to the skies, some experts are questioning if having such packed out planes is putting passengers at risk. They say that the shrinking space on aeroplanes is not only uncomfortable - it's putting our health and safety in danger. More than squabbling over the arm rest, shrinking space on planes putting our health and safety in danger? This week, a U.S consumer advisory group set up by the Department of Transportation said at a public hearing that while the government is happy to set standards for animals flying on planes, it doesn't stipulate a minimum amount of space for humans. 'In a world where animals have more rights to space and food than humans,' said Charlie Leocha, consumer representative on the committee.Â 'It is time that the DOT and FAA take a stand for humane treatment of passengers.' But could crowding on planes lead to more serious issues than fighting for space in the overhead lockers, crashing elbows and seat back kicking? Tests conducted by the FAA use planes with a 31 inch pitch, a standard which on some airlines has decreased . Many economy seats on United Airlines have 30 inches of room, while some airlines offer as little as 28 inches . Cynthia Corbertt, a human factors researcher with the Federal Aviation Administration, that it conducts tests on how quickly passengers can leave a plane. But these tests are conducted using planes with 31 inches between each row of seats, a standard which on some airlines has decreased, reported the Detroit News. The distance between two seats from one point on a seat to the same point on the seat behind it is known as the pitch. While most airlines stick to a pitch of 31 inches or above, some fall below this. While United Airlines has 30 inches of space, Gulf Air economy seats have between 29 and 32 inches, Air Asia offers 29 inches and Spirit Airlines offers just 28 inches. British Airways has a seat pitch of 31 inches, while easyJet has 29 inches, Thomson's short haul seat pitch is 28 inches, and Virgin Atlantic's is 30-31.\n",
            "\n",
            "Summary:\n",
            "  U.S consumer advisory group set up by the Department of Transportation said that while the government is happy to set standards for animals flying on planes, it doesn't stipulate a minimum amount of space for humans . Many economy seats on United Airlines have 30 inches of room, while some airlines offer as little as 28 inches .\n",
            "\n",
            "Number of words in article: 370\n",
            "Number of words in summary: 58\n"
          ]
        }
      ],
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "# Load the BERT-based text summarization pipeline\n",
        "summarization_pipeline = pipeline(\"summarization\")\n",
        "\n",
        "# Function to generate summary using BERT\n",
        "def generate_summary_bert(article):\n",
        "    summarized_text = summarization_pipeline(article, max_length=150, min_length=30, do_sample=False)\n",
        "    summary = summarized_text[0]['summary_text']\n",
        "    return summary\n",
        "\n",
        "# Main function with BERT summarization\n",
        "def main_bert(article_id):\n",
        "    # Get article based on article_id\n",
        "    article = df.loc[df['id'] == article_id]['article'].values[0]\n",
        "\n",
        "    # Generate summary using BERT\n",
        "    summary = generate_summary_bert(article)\n",
        "\n",
        "    # Count the number of words in article and summary\n",
        "    article_word_count = len(article.split())\n",
        "    summary_word_count = len(summary.split())\n",
        "\n",
        "    # Print article, summary, and word counts\n",
        "    print(\"Article:\\n\", article)\n",
        "    print(\"\\nSummary:\\n\", summary)\n",
        "    print(\"\\nNumber of words in article:\", article_word_count)\n",
        "    print(\"Number of words in summary:\", summary_word_count)\n",
        "\n",
        "# Test the BERT-based summarization function\n",
        "article_id = '92c514c913c0bdfe25341af9fd72b29db544099b'  # Example ID\n",
        "main_bert(article_id)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LZAc0n_Cau4K",
        "outputId": "316bde84-7512-49c7-e741-a7431e5da5ee"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "No model was supplied, defaulted to sshleifer/distilbart-cnn-12-6 and revision a4f8f3e (https://huggingface.co/sshleifer/distilbart-cnn-12-6).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Article:\n",
            " Ever noticed how plane seats appear to be getting smaller and smaller? With\n",
            "increasing numbers of people taking to the skies, some experts are questioning\n",
            "if having such packed out planes is putting passengers at risk. They say that\n",
            "the shrinking space on aeroplanes is not only uncomfortable - it's putting our\n",
            "health and safety in danger. More than squabbling over the arm rest, shrinking\n",
            "space on planes putting our health and safety in danger? This week, a U.S\n",
            "consumer advisory group set up by the Department of Transportation said at a\n",
            "public hearing that while the government is happy to set standards for animals\n",
            "flying on planes, it doesn't stipulate a minimum amount of space for humans. 'In\n",
            "a world where animals have more rights to space and food than humans,' said\n",
            "Charlie Leocha, consumer representative on the committee.Â 'It is time that the\n",
            "DOT and FAA take a stand for humane treatment of passengers.' But could crowding\n",
            "on planes lead to more serious issues than fighting for space in the overhead\n",
            "lockers, crashing elbows and seat back kicking? Tests conducted by the FAA use\n",
            "planes with a 31 inch pitch, a standard which on some airlines has decreased .\n",
            "Many economy seats on United Airlines have 30 inches of room, while some\n",
            "airlines offer as little as 28 inches . Cynthia Corbertt, a human factors\n",
            "researcher with the Federal Aviation Administration, that it conducts tests on\n",
            "how quickly passengers can leave a plane. But these tests are conducted using\n",
            "planes with 31 inches between each row of seats, a standard which on some\n",
            "airlines has decreased, reported the Detroit News. The distance between two\n",
            "seats from one point on a seat to the same point on the seat behind it is known\n",
            "as the pitch. While most airlines stick to a pitch of 31 inches or above, some\n",
            "fall below this. While United Airlines has 30 inches of space, Gulf Air economy\n",
            "seats have between 29 and 32 inches, Air Asia offers 29 inches and Spirit\n",
            "Airlines offers just 28 inches. British Airways has a seat pitch of 31 inches,\n",
            "while easyJet has 29 inches, Thomson's short haul seat pitch is 28 inches, and\n",
            "Virgin Atlantic's is 30-31.\n",
            "\n",
            "Summary:\n",
            "  U.S consumer advisory group set up by the Department of Transportation said\n",
            "that while the government is happy to set standards for animals flying on\n",
            "planes, it doesn't stipulate a minimum amount of space for humans . Many economy\n",
            "seats on United Airlines have 30 inches of room, while some airlines offer as\n",
            "little as 28 inches .\n",
            "\n",
            "Number of words in article: 370\n",
            "Number of words in summary: 58\n"
          ]
        }
      ],
      "source": [
        "import textwrap\n",
        "from transformers import pipeline\n",
        "\n",
        "# Load the BERT-based text summarization pipeline\n",
        "summarization_pipeline = pipeline(\"summarization\")\n",
        "\n",
        "# Function to generate summary using BERT\n",
        "def generate_summary_bert(article):\n",
        "    summarized_text = summarization_pipeline(article, max_length=150, min_length=30, do_sample=False)\n",
        "    summary = summarized_text[0]['summary_text']\n",
        "    return summary\n",
        "\n",
        "# Main function with BERT summarization\n",
        "def main_bert(article_id):\n",
        "    # Get article based on article_id\n",
        "    article = df.loc[df['id'] == article_id]['article'].values[0]\n",
        "\n",
        "    # Generate summary using BERT\n",
        "    summary = generate_summary_bert(article)\n",
        "\n",
        "    # Count the number of words in article and summary\n",
        "    article_word_count = len(article.split())\n",
        "    summary_word_count = len(summary.split())\n",
        "\n",
        "    # Word wrap article and summary\n",
        "    wrapper = textwrap.TextWrapper(width=80)\n",
        "    article_wrapped = wrapper.fill(text=article)\n",
        "    summary_wrapped = wrapper.fill(text=summary)\n",
        "\n",
        "    # Print article, summary, and word counts\n",
        "    print(\"Article:\\n\", article_wrapped)\n",
        "    print(\"\\nSummary:\\n\", summary_wrapped)\n",
        "    print(\"\\nNumber of words in article:\", article_word_count)\n",
        "    print(\"Number of words in summary:\", summary_word_count)\n",
        "\n",
        "# Test the BERT-based summarization function\n",
        "article_id = '92c514c913c0bdfe25341af9fd72b29db544099b'  # Example ID\n",
        "main_bert(article_id)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZCT59ZcwcUjk",
        "outputId": "0223591e-9860-49a6-8bbc-cb85b1c13a47"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "No model was supplied, defaulted to sshleifer/distilbart-cnn-12-6 and revision a4f8f3e (https://huggingface.co/sshleifer/distilbart-cnn-12-6).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Article:\n",
            " Ever noticed how plane seats appear to be getting smaller and smaller? With\n",
            "increasing numbers of people taking to the skies, some experts are questioning\n",
            "if having such packed out planes is putting passengers at risk. They say that\n",
            "the shrinking space on aeroplanes is not only uncomfortable - it's putting our\n",
            "health and safety in danger. More than squabbling over the arm rest, shrinking\n",
            "space on planes putting our health and safety in danger? This week, a U.S\n",
            "consumer advisory group set up by the Department of Transportation said at a\n",
            "public hearing that while the government is happy to set standards for animals\n",
            "flying on planes, it doesn't stipulate a minimum amount of space for humans. 'In\n",
            "a world where animals have more rights to space and food than humans,' said\n",
            "Charlie Leocha, consumer representative on the committee.Â 'It is time that the\n",
            "DOT and FAA take a stand for humane treatment of passengers.' But could crowding\n",
            "on planes lead to more serious issues than fighting for space in the overhead\n",
            "lockers, crashing elbows and seat back kicking? Tests conducted by the FAA use\n",
            "planes with a 31 inch pitch, a standard which on some airlines has decreased .\n",
            "Many economy seats on United Airlines have 30 inches of room, while some\n",
            "airlines offer as little as 28 inches . Cynthia Corbertt, a human factors\n",
            "researcher with the Federal Aviation Administration, that it conducts tests on\n",
            "how quickly passengers can leave a plane. But these tests are conducted using\n",
            "planes with 31 inches between each row of seats, a standard which on some\n",
            "airlines has decreased, reported the Detroit News. The distance between two\n",
            "seats from one point on a seat to the same point on the seat behind it is known\n",
            "as the pitch. While most airlines stick to a pitch of 31 inches or above, some\n",
            "fall below this. While United Airlines has 30 inches of space, Gulf Air economy\n",
            "seats have between 29 and 32 inches, Air Asia offers 29 inches and Spirit\n",
            "Airlines offers just 28 inches. British Airways has a seat pitch of 31 inches,\n",
            "while easyJet has 29 inches, Thomson's short haul seat pitch is 28 inches, and\n",
            "Virgin Atlantic's is 30-31.\n",
            "\n",
            "Summary:\n",
            "  U.S consumer advisory group set up by the Department of Transportation said\n",
            "that while the government is happy to set standards for animals flying on\n",
            "planes, it doesn't stipulate a minimum amount of space for humans . Many economy\n",
            "seats on United Airlines have 30 inches of room, while some airlines offer as\n",
            "little as 28 inches .\n",
            "\n",
            "Number of words in article: 370\n",
            "Number of words in summary: 58\n",
            "\n",
            "ROUGE scores:\n",
            "[{'rouge-1': {'r': 0.30303030303030304, 'p': 0.20833333333333334, 'f': 0.24691357541838144}, 'rouge-2': {'r': 0.15151515151515152, 'p': 0.08928571428571429, 'f': 0.11235954589572043}, 'rouge-l': {'r': 0.30303030303030304, 'p': 0.20833333333333334, 'f': 0.24691357541838144}}]\n"
          ]
        }
      ],
      "source": [
        "import textwrap\n",
        "from transformers import pipeline\n",
        "from rouge import Rouge\n",
        "\n",
        "# Load the BERT-based text summarization pipeline\n",
        "summarization_pipeline = pipeline(\"summarization\")\n",
        "\n",
        "# Function to generate summary using BERT\n",
        "def generate_summary_bert(article):\n",
        "    summarized_text = summarization_pipeline(article, max_length=150, min_length=30, do_sample=False)\n",
        "    summary = summarized_text[0]['summary_text']\n",
        "    return summary\n",
        "\n",
        "# Main function with BERT summarization\n",
        "def main_bert(article_id):\n",
        "    # Get article based on article_id\n",
        "    article = df.loc[df['id'] == article_id]['article'].values[0]\n",
        "\n",
        "    # Generate summary using BERT\n",
        "    summary = generate_summary_bert(article)\n",
        "\n",
        "    # Count the number of words in article and summary\n",
        "    article_word_count = len(article.split())\n",
        "    summary_word_count = len(summary.split())\n",
        "\n",
        "    # Word wrap article and summary\n",
        "    wrapper = textwrap.TextWrapper(width=80)\n",
        "    article_wrapped = wrapper.fill(text=article)\n",
        "    summary_wrapped = wrapper.fill(text=summary)\n",
        "\n",
        "    # Print article, summary, and word counts\n",
        "    print(\"Article:\\n\", article_wrapped)\n",
        "    print(\"\\nSummary:\\n\", summary_wrapped)\n",
        "    print(\"\\nNumber of words in article:\", article_word_count)\n",
        "    print(\"Number of words in summary:\", summary_word_count)\n",
        "\n",
        "    # Calculate ROUGE scores\n",
        "    rouge = Rouge()\n",
        "    rouge_scores = rouge.get_scores(summary, df.loc[df['id'] == article_id]['highlights'].values[0])\n",
        "    print(\"\\nROUGE scores:\")\n",
        "    print(rouge_scores)\n",
        "\n",
        "# Test the BERT-based summarization function\n",
        "article_id = '92c514c913c0bdfe25341af9fd72b29db544099b'  # Example ID\n",
        "main_bert(article_id)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sCICf_6ZdeLF",
        "outputId": "4052d2e6-e9b0-4a9a-aad2-a07837983b79"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "No model was supplied, defaulted to sshleifer/distilbart-cnn-12-6 and revision a4f8f3e (https://huggingface.co/sshleifer/distilbart-cnn-12-6).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Article:\n",
            " Ever noticed how plane seats appear to be getting smaller and smaller? With\n",
            "increasing numbers of people taking to the skies, some experts are questioning\n",
            "if having such packed out planes is putting passengers at risk. They say that\n",
            "the shrinking space on aeroplanes is not only uncomfortable - it's putting our\n",
            "health and safety in danger. More than squabbling over the arm rest, shrinking\n",
            "space on planes putting our health and safety in danger? This week, a U.S\n",
            "consumer advisory group set up by the Department of Transportation said at a\n",
            "public hearing that while the government is happy to set standards for animals\n",
            "flying on planes, it doesn't stipulate a minimum amount of space for humans. 'In\n",
            "a world where animals have more rights to space and food than humans,' said\n",
            "Charlie Leocha, consumer representative on the committee.Â 'It is time that the\n",
            "DOT and FAA take a stand for humane treatment of passengers.' But could crowding\n",
            "on planes lead to more serious issues than fighting for space in the overhead\n",
            "lockers, crashing elbows and seat back kicking? Tests conducted by the FAA use\n",
            "planes with a 31 inch pitch, a standard which on some airlines has decreased .\n",
            "Many economy seats on United Airlines have 30 inches of room, while some\n",
            "airlines offer as little as 28 inches . Cynthia Corbertt, a human factors\n",
            "researcher with the Federal Aviation Administration, that it conducts tests on\n",
            "how quickly passengers can leave a plane. But these tests are conducted using\n",
            "planes with 31 inches between each row of seats, a standard which on some\n",
            "airlines has decreased, reported the Detroit News. The distance between two\n",
            "seats from one point on a seat to the same point on the seat behind it is known\n",
            "as the pitch. While most airlines stick to a pitch of 31 inches or above, some\n",
            "fall below this. While United Airlines has 30 inches of space, Gulf Air economy\n",
            "seats have between 29 and 32 inches, Air Asia offers 29 inches and Spirit\n",
            "Airlines offers just 28 inches. British Airways has a seat pitch of 31 inches,\n",
            "while easyJet has 29 inches, Thomson's short haul seat pitch is 28 inches, and\n",
            "Virgin Atlantic's is 30-31.\n",
            "\n",
            "Summary:\n",
            "  U.S consumer advisory group set up by the Department of Transportation said\n",
            "that while the government is happy to set standards for animals flying on\n",
            "planes, it doesn't stipulate a minimum amount of space for humans . Many economy\n",
            "seats on United Airlines have 30 inches of room, while some airlines offer as\n",
            "little as 28 inches . British Airways has a seat pitch of 31 inches, while\n",
            "easyJet has 29 inches, Thomson's short haul seat pitch is 28 inches, Virgin\n",
            "Atlantic's is 30-31. While United Airlines has 30 inches, Gulf Air economy seats\n",
            "have between 29 and 32 inches, Air Asia offers 29 inches and Spirit Airlines\n",
            "offers just 28 inches. While most airlines stick to a pitch of 30 inches or\n",
            "above, some fall below this .\n",
            "\n",
            "Number of words in article: 370\n",
            "Number of words in summary: 129\n",
            "\n",
            "ROUGE scores:\n",
            "[{'rouge-1': {'r': 0.30303030303030304, 'p': 0.125, 'f': 0.1769911463074635}, 'rouge-2': {'r': 0.15151515151515152, 'p': 0.041666666666666664, 'f': 0.06535947374086908}, 'rouge-l': {'r': 0.30303030303030304, 'p': 0.125, 'f': 0.1769911463074635}}]\n"
          ]
        }
      ],
      "source": [
        "import textwrap\n",
        "from transformers import pipeline\n",
        "from rouge import Rouge\n",
        "\n",
        "# Load the BERT-based text summarization pipeline\n",
        "summarization_pipeline = pipeline(\"summarization\")\n",
        "\n",
        "# Function to generate summary using BERT\n",
        "def generate_summary_bert(article):\n",
        "    # Adjust max_length and min_length parameters to control summary length\n",
        "    summarized_text = summarization_pipeline(article, max_length=300, min_length=150, do_sample=False)\n",
        "    summary = summarized_text[0]['summary_text']\n",
        "    return summary\n",
        "\n",
        "# Main function with BERT summarization\n",
        "def main_bert(article_id):\n",
        "    # Get article based on article_id\n",
        "    article = df.loc[df['id'] == article_id]['article'].values[0]\n",
        "\n",
        "    # Generate summary using BERT\n",
        "    summary = generate_summary_bert(article)\n",
        "\n",
        "    # Count the number of words in article and summary\n",
        "    article_word_count = len(article.split())\n",
        "    summary_word_count = len(summary.split())\n",
        "\n",
        "    # Word wrap article and summary\n",
        "    wrapper = textwrap.TextWrapper(width=80)\n",
        "    article_wrapped = wrapper.fill(text=article)\n",
        "    summary_wrapped = wrapper.fill(text=summary)\n",
        "\n",
        "    # Print article, summary, and word counts\n",
        "    print(\"Article:\\n\", article_wrapped)\n",
        "    print(\"\\nSummary:\\n\", summary_wrapped)\n",
        "    print(\"\\nNumber of words in article:\", article_word_count)\n",
        "    print(\"Number of words in summary:\", summary_word_count)\n",
        "\n",
        "    # Calculate ROUGE scores\n",
        "    rouge = Rouge()\n",
        "    rouge_scores = rouge.get_scores(summary, df.loc[df['id'] == article_id]['highlights'].values[0])\n",
        "    print(\"\\nROUGE scores:\")\n",
        "    print(rouge_scores)\n",
        "\n",
        "# Test the BERT-based summarization function\n",
        "article_id = '92c514c913c0bdfe25341af9fd72b29db544099b'  # Example ID\n",
        "main_bert(article_id)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M77a4RyfeEXF",
        "outputId": "3349dfda-65a8-4bf5-d6b2-f71845cdfd44"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GPT-2 Summary:\n",
            "\n",
            "Article:\n",
            " Ever noticed how plane seats appear to be getting smaller and smaller? With increasing numbers of people taking to the skies, some experts are questioning if having such packed out planes is putting passengers at risk. They say that the shrinking space on aeroplanes is not only uncomfortable - it's putting our health and safety in danger. More than squabbling over the arm rest, shrinking space on planes putting our health and safety in danger? This week, a U.S consumer advisory group set up by the Department of Transportation said at a public hearing that while the government is happy to set standards for animals flying on planes, it doesn't stipulate a minimum amount of space for humans. 'In a world where animals have more rights to space and food than humans,' said Charlie Leocha, consumer representative on the committee.Â 'It is time that the DOT and FAA take a stand for humane treatment of passengers.' But could crowding on planes lead to more serious issues than fighting for space in the overhead lockers, crashing elbows and seat back kicking? Tests conducted by the FAA use planes with a 31 inch pitch, a standard which on some airlines has decreased . Many economy seats on United Airlines have 30 inches of room, while some airlines offer as little as 28 inches . Cynthia Corbertt, a human factors researcher with the Federal Aviation Administration, that it conducts tests on how quickly passengers can leave a plane. But these tests are conducted using planes with 31 inches between each row of seats, a standard which on some airlines has decreased, reported the Detroit News. The distance between two seats from one point on a seat to the same point on the seat behind it is known as the pitch. While most airlines stick to a pitch of 31 inches or above, some fall below this. While United Airlines has 30 inches of space, Gulf Air economy seats have between 29 and 32 inches, Air Asia offers 29 inches and Spirit Airlines offers just 28 inches. British Airways has a seat pitch of 31 inches, while easyJet has 29 inches, Thomson's short haul seat pitch is 28 inches, and Virgin Atlantic's is 30-31.\n",
            "\n",
            "Summary:\n",
            " summarize: Ever noticed how plane seats appear to be getting smaller and smaller? With increasing numbers of people taking to the skies, some experts are questioning if having such packed out planes is putting passengers at risk. They say that the shrinking space on aeroplanes is not only uncomfortable - it's putting our health and safety in danger. More than squabbling over the arm rest, shrinking space on planes putting our health and safety in danger? This week, a U.S consumer advisory group set up by the Department of Transportation said at a public hearing that while the government is happy to set standards for animals flying on planes, it doesn't stipulate a minimum amount of space for humans. 'In a world where animals have more rights to space and food than humans,' said Charlie Leocha, consumer representative on the committee.Â 'It is time that the DOT and FAA take a stand for humane treatment of passengers.' But could crowding on planes lead to more serious issues than fighting for space in the overhead lockers, crashing elbows and seat back kicking? Tests conducted by the FAA use planes with a 31 inch pitch, a standard which on some airlines has decreased. Many economy seats on United Airlines have 30 inches of room, while some airlines offer as little as 28 inches. Cynthia Corbertt, a human factors researcher with the Federal Aviation Administration, that it conducts tests on how quickly passengers can leave a plane. But these tests are conducted using planes with 31 inches between each row of seats, a standard which on some airlines has decreased, reported the Detroit News. The distance between two seats from one point on a seat to the same point on the seat behind it is known as the pitch. While most airlines stick to a pitch of 31 inches or above, some fall below this. While United Airlines has 30 inches of space, Gulf Air economy seats have between 29 and 32 inches, Air Asia offers 29 inches and Spirit Airlines offers just 28 inches. British Airways has a seat pitch of 31 inches, while easyJet has 29 inches, Thomson's short haul seat pitch is 28 inches, and Virgin Atlantic's is 30-31. Some airlines, such as United Airlines, offer as little as 28 inches, while others offer as little as\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
        "\n",
        "# Load the dataset\n",
        "file_path = \"test.csv\"\n",
        "dataset = pd.read_csv(file_path)\n",
        "\n",
        "# Load GPT-2 model and tokenizer\n",
        "gpt2_tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
        "gpt2_model = GPT2LMHeadModel.from_pretrained('gpt2')\n",
        "\n",
        "# Function for text summarization using GPT-2 model\n",
        "def generate_summary_gpt2(text):\n",
        "    inputs = gpt2_tokenizer.encode(\"summarize: \" + text, return_tensors=\"pt\", max_length=1024, truncation=True)\n",
        "    summary_ids = gpt2_model.generate(inputs, max_length=450, min_length=40, length_penalty=2.0, num_beams=4, early_stopping=True)\n",
        "    summary = gpt2_tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
        "    return summary\n",
        "\n",
        "# Find article and summary based on ID '92c514c913c0bdfe25341af9fd72b29db544099b'\n",
        "article_gpt2 = dataset.loc[dataset['id'] == '92c514c913c0bdfe25341af9fd72b29db544099b']['article'].values[0]\n",
        "summary_gpt2 = generate_summary_gpt2(article_gpt2)\n",
        "\n",
        "# Print the article and summary\n",
        "print(\"GPT-2 Summary:\")\n",
        "print(\"\\nArticle:\\n\", article_gpt2)\n",
        "print(\"\\nSummary:\\n\", summary_gpt2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z13lJTQNwm0-",
        "outputId": "3ea47a53-02bf-4fff-e9af-be2deaf06a99"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Column names in the dataset:\n",
            "Index(['id', 'article', 'highlights'], dtype='object')\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the dataset\n",
        "file_path = \"test.csv\"\n",
        "dataset = pd.read_csv(file_path)\n",
        "\n",
        "# Display column names\n",
        "print(\"Column names in the dataset:\")\n",
        "print(dataset.columns)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ItZopKDy4Qd",
        "outputId": "87647133-439f-4857-dfc9-ce216a8bb50a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GPT-2 Summary:\n",
            "\n",
            "Article:\n",
            " Ever noticed how plane seats appear to be getting smaller and smaller? With\n",
            "increasing numbers of people taking to the skies, some experts are questioning\n",
            "if having such packed out planes is putting passengers at risk. They say that\n",
            "the shrinking space on aeroplanes is not only uncomfortable - it's putting our\n",
            "health and safety in danger. More than squabbling over the arm rest, shrinking\n",
            "space on planes putting our health and safety in danger? This week, a U.S\n",
            "consumer advisory group set up by the Department of Transportation said at a\n",
            "public hearing that while the government is happy to set standards for animals\n",
            "flying on planes, it doesn't stipulate a minimum amount of space for humans. 'In\n",
            "a world where animals have more rights to space and food than humans,' said\n",
            "Charlie Leocha, consumer representative on the committee.Â 'It is time that the\n",
            "DOT and FAA take a stand for humane treatment of passengers.' But could crowding\n",
            "on planes lead to more serious issues than fighting for space in the overhead\n",
            "lockers, crashing elbows and seat back kicking? Tests conducted by the FAA use\n",
            "planes with a 31 inch pitch, a standard which on some airlines has decreased .\n",
            "Many economy seats on United Airlines have 30 inches of room, while some\n",
            "airlines offer as little as 28 inches . Cynthia Corbertt, a human factors\n",
            "researcher with the Federal Aviation Administration, that it conducts tests on\n",
            "how quickly passengers can leave a plane. But these tests are conducted using\n",
            "planes with 31 inches between each row of seats, a standard which on some\n",
            "airlines has decreased, reported the Detroit News. The distance between two\n",
            "seats from one point on a seat to the same point on the seat behind it is known\n",
            "as the pitch. While most airlines stick to a pitch of 31 inches or above, some\n",
            "fall below this. While United Airlines has 30 inches of space, Gulf Air economy\n",
            "seats have between 29 and 32 inches, Air Asia offers 29 inches and Spirit\n",
            "Airlines offers just 28 inches. British Airways has a seat pitch of 31 inches,\n",
            "while easyJet has 29 inches, Thomson's short haul seat pitch is 28 inches, and\n",
            "Virgin Atlantic's is 30-31.\n",
            "\n",
            "Summary:\n",
            " summarize: Ever noticed how plane seats appear to be getting smaller and\n",
            "smaller? With increasing numbers of people taking to the skies, some experts are\n",
            "questioning if having such packed out planes is putting passengers at risk. They\n",
            "say that the shrinking space on aeroplanes is not only uncomfortable - it's\n",
            "putting our health and safety in danger. More than squabbling over the arm rest,\n",
            "shrinking space on planes putting our health and safety in danger? This week, a\n",
            "U.S consumer advisory group set up by the Department of Transportation said at a\n",
            "public hearing that while the government is happy to set standards for animals\n",
            "flying on planes, it doesn't stipulate a minimum amount of space for humans. 'In\n",
            "a world where animals have more rights to space and food than humans,' said\n",
            "Charlie Leocha, consumer representative on the committee.Â 'It is time that the\n",
            "DOT and FAA take a stand for humane treatment of passengers.' But could crowding\n",
            "on planes lead to more serious issues than fighting for space in the overhead\n",
            "lockers, crashing elbows and seat back kicking? Tests conducted by the FAA use\n",
            "planes with a 31 inch pitch, a standard which on some airlines has decreased.\n",
            "Many economy seats on United Airlines have 30 inches of room, while some\n",
            "airlines offer as little as 28 inches. Cynthia Corbertt, a human factors\n",
            "researcher with the Federal Aviation Administration, that it conducts tests on\n",
            "how quickly passengers can leave a plane. But these tests are conducted using\n",
            "planes with 31 inches between each row of seats, a standard which on some\n",
            "airlines has decreased, reported the Detroit News. The distance between two\n",
            "seats from one point on a seat to the same point on the seat behind it is known\n",
            "as the pitch. While most airlines stick to a pitch of 31 inches or above, some\n",
            "fall below this. While United Airlines has 30 inches of space, Gulf Air economy\n",
            "seats have between 29 and 32 inches, Air Asia offers 29 inches and Spirit\n",
            "Airlines offers just 28 inches. British Airways has a seat pitch of 31 inches,\n",
            "while easyJet has 29 inches, Thomson's short haul seat pitch is 28 inches, and\n",
            "Virgin Atlantic's is 30-31. Some airlines, such as United Airlines, offer as\n",
            "little as 28 inches, while others offer as little as\n",
            "\n",
            "Number of words in article: 370\n",
            "Number of words in summary: 387\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import textwrap\n",
        "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
        "\n",
        "# Load the dataset\n",
        "file_path = \"test.csv\"\n",
        "dataset = pd.read_csv(file_path)\n",
        "\n",
        "# Load GPT-2 model and tokenizer\n",
        "gpt2_tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
        "gpt2_model = GPT2LMHeadModel.from_pretrained('gpt2')\n",
        "\n",
        "# Function for text summarization using GPT-2 model\n",
        "def generate_summary_gpt2(text):\n",
        "    inputs = gpt2_tokenizer.encode(\"summarize: \" + text, return_tensors=\"pt\", max_length=1024, truncation=True)\n",
        "    summary_ids = gpt2_model.generate(inputs, max_length=450, min_length=40, length_penalty=2.0, num_beams=4, early_stopping=True)\n",
        "    summary = gpt2_tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
        "    return summary\n",
        "\n",
        "# Function to wrap text and count words\n",
        "def wrap_and_count(text):\n",
        "    wrapped_text = textwrap.fill(text, width=80)\n",
        "    word_count = len(text.split())\n",
        "    return wrapped_text, word_count\n",
        "\n",
        "# Find article and summary based on ID '92c514c913c0bdfe25341af9fd72b29db544099b'\n",
        "article_id = '92c514c913c0bdfe25341af9fd72b29db544099b'\n",
        "article_gpt2 = dataset.loc[dataset['id'] == article_id]['article'].values[0]\n",
        "summary_gpt2 = generate_summary_gpt2(article_gpt2)\n",
        "\n",
        "# Wrap article and summary and count words\n",
        "wrapped_article, article_word_count = wrap_and_count(article_gpt2)\n",
        "wrapped_summary, summary_word_count = wrap_and_count(summary_gpt2)\n",
        "\n",
        "# Print the article, summary, and word count\n",
        "print(\"GPT-2 Summary:\")\n",
        "print(\"\\nArticle:\\n\", wrapped_article)\n",
        "print(\"\\nSummary:\\n\", wrapped_summary)\n",
        "print(\"\\nNumber of words in article:\", article_word_count)\n",
        "print(\"Number of words in summary:\", summary_word_count)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kbrE3oiretPY"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
        "from rouge import Rouge\n",
        "\n",
        "# Load the dataset\n",
        "file_path = \"test.csv\"\n",
        "dataset = pd.read_csv(file_path)\n",
        "\n",
        "# Load GPT-2 model and tokenizer\n",
        "gpt2_tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
        "gpt2_model = GPT2LMHeadModel.from_pretrained('gpt2')\n",
        "\n",
        "# Function for text summarization using GPT-2 model\n",
        "def generate_summary_gpt2(text):\n",
        "    inputs = gpt2_tokenizer.encode(\"summarize: \" + text, return_tensors=\"pt\", max_length=1024, truncation=True)\n",
        "    summary_ids = gpt2_model.generate(inputs, max_length=150, min_length=40, length_penalty=2.0, num_beams=4, early_stopping=True)\n",
        "    summary = gpt2_tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
        "    return summary\n",
        "\n",
        "# Main function to process each article in the dataset\n",
        "def process_articles(dataset):\n",
        "    for index, row in dataset.iterrows():\n",
        "        article = row['article']\n",
        "        summary = generate_summary_gpt2(article)\n",
        "        print(\"GPT-2 Summary:\\n\", summary)\n",
        "\n",
        "# Call the main function\n",
        "process_articles(dataset)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "NdSAoJ7LfsZV",
        "outputId": "04aa74be-c24e-496d-8106-d56535aa4126"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GPT-2 Summary:\n",
            " summarize: Ever noticed how plane seats appear to be getting smaller and smaller? With increasing numbers of people taking to the skies, some experts are questioning if having such packed out planes is putting passengers at risk. They say that the shrinking space on aeroplanes is not only uncomfortable - it's putting our health and safety in danger. More than squabbling over the arm rest, shrinking space on planes putting our health and safety in danger? This week, a U.S consumer advisory group set up by the Department of Transportation said at a public hearing that while the government is happy to set standards for animals flying on planes, it doesn't stipulate a minimum amount of space for humans. 'In a world where animals have more rights to space and food than humans,' said Charlie Leocha, consumer representative on the committee.Â 'It is time that the DOT and FAA take a stand for humane treatment of passengers.' But could crowding on planes lead to more serious issues than fighting for space in the overhead lockers, crashing elbows and seat back kicking? Tests conducted by the FAA use planes with a 31 inch pitch, a standard which on some airlines has decreased. Many economy seats on United Airlines have 30 inches of room, while some airlines offer as little as 28 inches. Cynthia Corbertt, a human factors researcher with the Federal Aviation Administration, that it conducts tests on how quickly passengers can leave a plane. But these tests are conducted using planes with 31 inches between each row of seats, a standard which on some airlines has decreased, reported the Detroit News. The distance between two seats from one point on a seat to the same point on the seat behind it is known as the pitch. While most airlines stick to a pitch of 31 inches or above, some fall below this. While United Airlines has 30 inches of space, Gulf Air economy seats have between 29 and 32 inches, Air Asia offers 29 inches and Spirit Airlines offers just 28 inches. British Airways has a seat pitch of 31 inches, while easyJet has 29 inches, Thomson's short haul seat pitch is 28 inches, and Virgin Atlantic's is 30-31. Some airlines, such as United Airlines, offer as little as 28 inches of space, while others offer as little as 28 inches. Some airlines, such as United Airlines, offer as little as 28 inches of space, while others offer as little as 28 inches. Some airlines, such as United Airlines, offer as little as 28 inches of space, while others offer as little as 28 inches. Some airlines, such as United Airlines, offer as little as 28 inches of space, while others offer as little as 28 inches. Some airlines, such as United Airlines, offer as little as 28 inches of space, while others offer as little as 28 inches. Some airlines, such as United Airlines, offer as little as 28 inches of space, while others offer as little as 28 inches. Some airlines, such as United Airlines, offer as little as 28 inches of space, while others offer as little as 28 inches. Some airlines, such as United Airlines, offer as little as 28 inches of space, while others offer as little as 28 inches. Some airlines, such as United Airlines, offer as little as 28 inches of space, while others offer as little as 28 inches. Some airlines, such as United Airlines, offer as little as 28 inches of space, while others offer as little as 28 inches. Some airlines, such as United Airlines, offer as little as 28 inches of space, while others offer as little as 28 inches. Some airlines, such as United Airlines, offer as little as 28 inches of space, while others offer as little as 28 inches. Some airlines, such as United Airlines, offer as little as 28 inches of space, while others offer as little as 28 inches. Some airlines, such as United Airlines, offer as little as 28 inches of space, while others offer as little as 28 inches. Some airlines, such as United Airlines, offer as little as 28 inches of space, while others offer as little as 28 inches. Some airlines, such as United Airlines, offer as little as 28 inches of space, while others offer as little as 28 inches. Some airlines, such as United Airlines, offer as little as 28 inches of space, while others offer as little as 28 inches. Some airlines, such as United Airlines, offer as little as 28 inches of space, while others offer as little as 28 inches. Some airlines, such as United Airlines, offer as little as 28 inches of space, while others offer as little as 28 inches. Some airlines, such as United Airlines, offer as little as 28 inches of space, while others offer as little as 28 inches. Some airlines, such as United Airlines, offer as little as 28 inches of space, while others offer as little as 28 inches. Some airlines, such as United Airlines, offer as little as 28 inches of space, while others offer as little as 28 inches\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GPT-2 Summary:\n",
            " summarize: A drunk teenage boy had to be rescued by security after jumping into a lions' enclosure at a zoo in western India. Rahul Kumar, 17, clambered over the enclosure fence at theÂ Kamla Nehru Zoological Park in Ahmedabad, and began running towards the animals, shouting he would 'kill them'. Mr Kumar explained afterwards that he was drunk and 'thought I'd stand a good chance' against the predators. Next level drunk: Intoxicated Rahul Kumar, 17, climbed into the lions' enclosure at a zoo in Ahmedabad and began running towards the animals shouting 'Today I kill a lion!' Mr Kumar had been sitting near the enclosure when he suddenly made a dash for the lions, surprising zoo security. The intoxicated teenager ran towards the lions, shouting: 'Today I kill a lion or a lion kills me!' A zoo spokesman said: 'Guards had earlier spotted him close to the enclosure but had no idea he was planing to enter it. 'Fortunately, there are eight moats to cross before getting to where the lions usually are and he fell into the second one, allowing guards to catch up with him and take him out. 'We then handed him over to the police.' Brave fool: Fortunately, Mr Kumar  fell into a moat as he ran towards the lions and could be rescued by zoo security staff before reaching the animals (stock image) Kumar later explained: 'I don't really know why I did it. 'I was drunk and thought I'd stand a good chance.' A police spokesman said: 'He has been cautioned and will be sent for psychiatric evaluation. 'Fortunately for him, the lions were asleep and the zoo guards acted quickly enough to prevent a tragedy similar to that in Delhi.' Last year a 20-year-old man was mauled to death by a tiger in the Indian capital after climbing into its enclosure at the city zoo. Mr Kumar, who was in his 20s at the time of the incident, was rushed to the hospital where he was pronounced dead. Mr Kumar, who was in his 20s at the time of the incident, was rushed to the hospital where he was pronounced dead. Mr Kumar, who was in his 20s at the time of the incident, was rushed to the hospital where he was pronounced dead. Mr Kumar, who was in his 20s at the time of the incident, was rushed to the hospital where he was pronounced dead. Mr Kumar, who was in his 20s at the time of the incident, was rushed to the hospital where he was pronounced dead. Mr Kumar, who was in his 20s at the time of the incident, was rushed to the hospital where he was pronounced dead. Mr Kumar, who was in his 20s at the time of the incident, was rushed to the hospital where he was pronounced dead. Mr Kumar, who was in his 20s at the time of the incident, was rushed to the hospital where he was pronounced dead. Mr Kumar, who was in his 20s at the time of the incident, was rushed to the hospital where he was pronounced dead. Mr Kumar, who was in his 20s at the time of the incident, was rushed to the hospital where he was pronounced dead. Mr Kumar, who was in his 20s at the time of the incident, was rushed to the hospital where he was pronounced dead. Mr Kumar, who was in his 20s at the time of the incident, was rushed to the hospital where he was pronounced dead. Mr Kumar, who was in his 20s at the time of the incident, was rushed to the hospital where he was pronounced dead. Mr Kumar, who was in his 20s at the time of the incident, was rushed to the hospital where he was pronounced dead. Mr Kumar, who was in his 20s at the time of the incident, was rushed to the hospital where he was pronounced dead. Mr Kumar, who was in his 20s at the time of the incident, was rushed to the hospital where he was pronounced dead. Mr Kumar, who was in his 20s at the time of the incident, was rushed to the hospital where he was pronounced dead. Mr Kumar, who was in his 20s at the time of the incident, was rushed to the hospital where he was pronounced dead. Mr Kumar, who was in his 20s at the time of the incident, was rushed to the hospital where he was pronounced dead. Mr Kumar, who was in his 20s at the time of the incident, was rushed to the hospital where he was pronounced dead. Mr Kumar, who was in his 20s at the time of the incident, was rushed to the hospital where he was pronounced dead. Mr Kumar, who was in his 20s at the time of the incident, was rushed to the hospital where he was pronounced dead. Mr Kumar, who was in his 20s at the time of the incident, was rushed\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GPT-2 Summary:\n",
            " summarize: Dougie Freedman is on the verge of agreeing a new two-year deal to remain at Nottingham Forest. Freedman has stabilised Forest since he replaced cult hero Stuart Pearce and the club's owners are pleased with the job he has done at the City Ground. Dougie Freedman is set to sign a new deal at Nottingham Forest. Freedman has impressed at the City Ground since replacing Stuart Pearce in February. They made an audacious attempt on the play-off places when Freedman replaced Pearce but have tailed off in recent weeks. That has not prevented Forest's ownership making moves to secure Freedman on a contract for the next two seasons.\n",
            "\n",
            "Freedman is on the verge of agreeing a new two-year deal to remain at Nottingham Forest. Freedman has stabilised Forest since he replaced cult hero Stuart Pearce and the club's owners are pleased with the job he has done at the City Ground. Freedman has impressed at the City Ground since replacing Stuart Pearce in February. They made an audacious attempt on the play-off places when Freedman replaced Pearce but have tailed off in recent weeks. That has not prevented Forest's ownership making moves to secure Freedman on a contract for the next two seasons. Dougie Freedman is set to sign a new deal at Nottingham Forest. Freedman has impressed at the City Ground since replacing Stuart Pearce in February. They made an audacious attempt on the play-off places when Freedman replaced Pearce but have tailed off in recent weeks. That has not prevented Forest's ownership making moves to secure Freedman on a contract for the next two seasons. Dougie Freedman is set to sign a new deal at Nottingham Forest. Freedman has impressed at the City Ground since replacing Stuart Pearce in February. They made an audacious attempt on the play-off places when Freedman replaced Pearce but have tailed off in recent weeks. That has not prevented Forest's ownership making moves to secure Freedman on a contract for the next two seasons. Dougie Freedman is set to sign a new deal at Nottingham Forest. Freedman has impressed at the City Ground since replacing Stuart Pearce in February. They made an audacious attempt on the play-off places when Freedman replaced Pearce but have tailed off in recent weeks. That has not prevented Forest's ownership making moves to secure Freedman on a contract for the next two seasons. Dougie Freedman is set to sign a new deal at Nottingham Forest. Freedman has impressed at the City Ground since replacing Stuart Pearce in February. They made an audacious attempt on the play-off places when Freedman replaced Pearce but have tailed off in recent weeks. That has not prevented Forest's ownership making moves to secure Freedman on a contract for the next two seasons. Dougie Freedman is set to sign a new deal at Nottingham Forest. Freedman has impressed at the City Ground since replacing Stuart Pearce in February. They made an audacious attempt on the play-off places when Freedman replaced Pearce but have tailed off in recent weeks. That has not prevented Forest's ownership making moves to secure Freedman on a contract for the next two seasons. Dougie Freedman is set to sign a new deal at Nottingham Forest. Freedman has impressed at the City Ground since replacing Stuart Pearce in February. They made an audacious attempt on the play-off places when Freedman replaced Pearce but have tailed off in recent weeks. That has not prevented Forest's ownership making moves to secure Freedman on a contract for the next two seasons. Dougie Freedman is set to sign a new deal at Nottingham Forest. Freedman has impressed at the City Ground since replacing Stuart Pearce in February. They made an audacious attempt on the play-off places when Freedman replaced Pearce but have tailed off in recent weeks. That has not prevented Forest's ownership making moves to secure Freedman on a contract for the next two seasons. Dougie Freedman is set to sign a new deal at Nottingham Forest. Freedman has impressed at the City Ground since replacing Stuart Pearce in February. They made an audacious attempt on the play-off places when Freedman replaced Pearce but have tailed off in recent weeks. That has not prevented Forest's ownership making moves to secure Freedman on a contract for the next two seasons. Dougie Freedman is set to sign a new deal at Nottingham Forest. Freedman has impressed at the City Ground since replacing Stuart Pearce in February. They made an audacious attempt on the play-off places when Freedman replaced Pearce but have tailed off in recent weeks. That has not prevented Forest's ownership making moves to secure Freedman on a contract for the next two seasons. Dougie Freedman is set to sign a new deal at Nottingham Forest. Freedman has impressed at the City Ground since replacing Stuart Pearce in February. They made an audacious attempt on the play-off places when Freedman replaced\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GPT-2 Summary:\n",
            " summarize: Liverpool target Neto is also wanted by PSG and clubs in Spain as Brendan Rodgers faces stiff competition to land the Fiorentina goalkeeper, according to the Brazilian's agent Stefano Castagna. The Reds were linked with a move for the 25-year-old, whose contract expires in June, earlier in the season when Simon Mignolet was dropped from the side. A January move for Neto never materialised but the former Atletico Paranaense keeper looks certain to leave the Florence-based club in the summer. Neto rushes from his goal as Juan Iturbe bears down on him during Fiorentina's clash with Roma in March. Neto is wanted by a number of top European clubs including Liverpool and PSG, according to his agent. It had been reported that Neto had a verbal agreement to join Serie A champions Juventus at the end of the season but his agent has revealed no decision about his future has been made yet. And Castagna claims Neto will have his pick of top European clubs when the transfer window re-opens in the summer, including Brendan Rodgers' side. 'There are many European clubs interested in Neto, such as for example Liverpool and Paris Saint-Germain,' Stefano Castagna is quoted as saying by Gazzetta TV. Firoentina goalkeeper Neto saves at the feet of Tottenham midfielder Nacer Chadli in the Europa League. 'In Spain too there are clubs at the very top level who are tracking him. Real Madrid? We'll see. 'We have not made a definitive decision, but in any case he will not accept another loan move elsewhere.' Neto, who represented Brazil at the London 2012 Olympics but has not featured for the senior side, was warned against joining a club as a No 2 by national coach Dunga. Neto joined Fiorentina fromÂ Atletico Paranaense in 2011 and established himself as No1 in the last two seasons. Neto has been linked with a move to Fiorentina but has not made a final decision on his future. 'I don't know if I will stay at Fiorentina or not,' he said. 'I don't know if I will stay at Fiorentina or not. I don't know if I will stay at Fiorentina or not. I don't know if I will stay at Fiorentina or not. I don't know if I will stay at Fiorentina or not.'\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GPT-2 Summary:\n",
            " summarize: Bruce Jenner will break his silence in a two-hour interview with Diane Sawyer later this month. The former Olympian and reality TV star, 65, will speak in a 'far-ranging' interview with Sawyer for a special edition of '20/20' on Friday April 24, ABC News announced on Monday. The interview comes amid growing speculation about the father-of-six's transition to a woman,Â and follows closely behind his involvement in a deadly car crash in California in February. And while the Kardashian women are known for enjoying center stage, they will not be stealing Bruce's spotlight because they will be in Armenia when the interview airs, according to TMZ. Scroll down for video. Speaking out: Bruce Jenner, pictured on 'Keeping Up with the Kardashians' will speak out in a 'far-ranging' interview with Diane Sawyer later this month, ABC News announced on Monday. Return: Diane Sawyer, who recently mourned the loss of her husband, will return to ABC for the interview. Rumors started swirling around Jenner's gender identity last year, when he emerged from a Beverly Hills clinic with his Adam's apple shaved down. His behavior over the past year also fueled speculation as he began embracing an increasingly female appearance, including growing out his hair, shaving his legs and painting hisÂ nails, while reportedly undergoing hormone therapy. He also split from with his wife of more than two decades, Kris Jenner, with whom he has two daughters, Kyle and Kendall. She filed for divorce in September 2014, citing 'irreconcilable differences'. Reports also emerged over the past week that he has received a breast enhancement. 'Bruce had silicone breast implants put in a few weeks ago,' a source told RadarOnline. 'He went with a smaller implant because he didn't want to look ridiculous.' On Sunday, he was seen walking to his car in Malibu but hid his body beneath a bulky sweatshirt. Out and about: Jenner was pictured walking back to his car in Malibu on the weekend and hiding beneath a large sweatshirt on Sunday, days after reports that he had undergone a breast enhancement. Hiding: He also apparently had painted his nails red when he was seen walking on Sunday. According to Radar, Jenner wants to have all surgeries completed in time to make his on-screen debut as a woman on the fall season of 'Dancing with the Stars'. Jenner is also rumored to be filming a spin-off docu-series about the transitionÂ on E!, although his reps have refused to confirm the claims. While Jenner himself has remained silent about his reported transition, some of his relatives, including step-daughter Kim Kardashian, have spoken about about his 'journey'. 'I guess I'll kind of let everyone be curious and I feel like that's his journey to talk about,' Kim recently told Entertainment Tonight. 'I will say that I think Bruce should tell his story his way. I think everyone goes through things in life and I think that story and what Bruce is going through, I think he'll share whenever the time is right.' Jenner, who won gold in the decathlon at the 1976 Olympics, also made headlines earlier this year for his involvement in a deadly car crash in Malibu. Deadly: In February, Jenner's vehicle, which was pulling a trailer and an ATV (seen right) rear-ended a woman's car (left) and pushed it into the lane of an oncoming Hummer. She died at the scene. By his side: Bruce, pictured with his ex-wife Kris Jenner and four of his step-children (from left) Rob, Kim, Kourtney and Khloe, has received support from his family. Kris filed for divorce from him last year. His Cadillac Escalade, which was pulling a trailer and off-road vehicle, plowed into the back of a Lexus and pushed it into the path of an oncoming HummerÂ on February 7. The Lexus was carrying 69-year-old Kim Howe, who died from chest trauma at the scene. Police sources say Jenner is unlikely to be prosecuted because he wasn't drinking, speeding or texting at the time of the fatal crash. His tell-all interview will also be one of Sawyer's first forays back to TV news following the death of her husband, acclaimed director Mike Nichols, following a heart attack last November. Last September, she left the anchor chair of ABC World News and announced that she planned to focus on specials. In February, she presented 'A Nation of Women Behind Bars', in which she went to prisons across the country to speak with female inmates. In a statement, she said: 'I am deeply saddened by the tragic death of my husband and his family. My thoughts and prayers go out to the family and friends of my husband and his family. My thoughts and prayers go out to the family and friends of my husband and his family. My thoughts and prayers\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GPT-2 Summary:\n",
            " summarize: This is the moment that a crew of firefighters struggled to haul a giant  pig out of a garden swimming pool. The prize porker, known  as Pigwig, had fallen into the pool in an upmarket neighbourhood in Ringwood, Hampshire. His owners had been taking him for a walk around the garden when the animal plunged into the water and was unable to get out. A team from Dorset Fire and Rescue struggled to haul the huge black pig out of swimming pool water. The prize porker known as Pigwig had fallen into the water and had then been unable to get out again. Two fire crews and a specialist animal rescue team had to use slide boards and strops to haul the huge black pig from the small pool. A spokesman for Dorset Fire and Rescue Service said: 'At 4.50pm yesterday the service received a call to a pig stuck in a swimming pool. 'One crew of firefighters from Ferndown and a specialist animal rescue unit from Poole were mobilised to this incident. 'Once in attendance the crew secured the pig with strops, and requested the attendance of another appliance which was mobilised from Ringwood by our colleagues in Hampshire Fire and Rescue Service. Firefighters were also called out to a horse which had fallen into a swimming pool in Heyshott, West Sussex. The exhausted animal had to be winched to using an all-terrain crane but appeared no worse for wear after its tumble. 'The crew rescued the pig from the swimming pool using specialist animal rescue slide boards, strops and lines to haul the pig from the swimming pool.' But Pigwig wasn't the only animal who needed rescuing after taking an unexpected swim. Crews in West Sussex were called out to a swimming pool where this time a horse had fallen in. Wet and very bedraggled, the exhausted animal put up no opposition when firefighters arrived to hoist her out of the small garden pool inÂ Heyshott. The two-hour rescue operation ended with the wayward horse being fitted with straps under her belly and lifted up into the air with an all-terrain crane before being swung around and deposited back on dry land. A fire brigade spokesman said that she appeared none the worse for her impromptu swim after stepping over the edge of the domestic pool. He said: 'The pig was taken to Dorset Fire and Rescue Service where she was taken to Poole Fire and Rescue Service where she was taken to Dorset Fire and Rescue Service where she was taken to Dorset Fire and Rescue Service where she was taken to Dorset Fire and Rescue Service where she was taken to Dorset Fire and Rescue Service where she was taken to Dorset Fire and Rescue Service where she was taken to Dorset Fire and Rescue Service where she was taken to Dorset Fire and Rescue Service where she was taken to Dorset Fire and Rescue Service where she was taken to Dorset Fire and Rescue Service where she was taken to Dorset Fire and Rescue Service where she was taken to Dorset Fire and Rescue Service where she was taken to Dorset Fire and Rescue Service where she was taken to Dorset Fire and Rescue Service where she was taken to Dorset Fire and Rescue Service where she was taken to Dorset Fire and Rescue Service where she was taken to Dorset Fire and Rescue Service where she was taken to Dorset Fire and Rescue Service where she was taken to Dorset Fire and Rescue Service where she was taken to Dorset Fire and Rescue Service where she was taken to Dorset Fire and Rescue Service where she was taken to Dorset Fire and Rescue Service where she was taken to Dorset Fire and Rescue Service where she was taken to Dorset Fire and Rescue Service where she was taken to Dorset Fire and Rescue Service where she was taken to Dorset Fire and Rescue Service where she was taken to Dorset Fire and Rescue Service where she was taken to Dorset Fire and Rescue Service where she was taken to Dorset Fire and Rescue Service where she was taken to Dorset Fire and Rescue Service where she was taken to Dorset Fire and Rescue Service where she was taken to Dorset Fire and Rescue Service where she was taken to Dorset Fire and Rescue Service where she was taken to Dorset Fire and Rescue Service where she was taken to Dorset Fire and Rescue Service where she was taken to Dorset Fire and Rescue Service where she was taken to Dorset Fire and Rescue Service where she was taken to Dorset Fire and Rescue Service where she was taken to Dorset Fire and Rescue Service where she was taken to Dorset Fire and Rescue Service where she was taken to Dorset Fire and Rescue Service where she was taken to Dorset Fire and Rescue Service where she was taken to Dorset Fire and Rescue Service where she was taken to Dorset Fire and Rescue Service where she was taken to Dorset Fire and Rescue Service where she was taken to Dorset Fire and Rescue Service where she was taken to Dorset Fire and Rescue\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GPT-2 Summary:\n",
            " summarize: The amount of time people spend listening to BBC radio has dropped to its lowest level ever, the corporationâ€™s boss has admitted. Figures show that while millions still tune in, they listen for much shorter bursts. The average listener spent just ten hours a week tuning in to BBC radio in the last three months of 2014, according to official figures. The length of time people spend listening to BBC radio has dropped to its lowest level ever, figures show. This was 14 per cent down on a decade earlier, when listeners clocked up an average of 11.6 hours a week. The minutes of the BBC Trustâ€™s February meeting, published yesterday, revealed that director general Tony Hall highlighted the fall. â€˜He notedâ€¦that time spent listening to BBC radio had dropped to its lowest ever level,â€™ the documents said. Sources blamed the downward trend on people leading faster-paced lives than in the past, and a change in habits amongst young people. Lord Tony Hall, BBC director general, highlighted the decline to the BBC Trust, according to minutes of its February meeting. Many people who used to listen to radio as a daily habit now turn to online streaming services such as Spotify for their music fix. That problem is likely to grow, as Apple develops its long-rumoured streaming service. A BBC spokesman said: â€˜The number of people listening to BBC radio stations and audience appreciation levels are as high as ever. â€˜But time spent listening has inevitably been affected by digital competition and as people â€˜tune inâ€™ in new, digital ways. â€˜[Those ways] arenâ€™t reflected in the traditional listening figures quoted here â€“ like watching videos from radio shows or listening to podcasts.â€™ BBC radio is still reaching 65 per cent of the population each week, according to the last set of figures available from RAJAR, the organisation which measures radio audiences. But although that figure feels relatively healthy by todayâ€™s standards, it has none the less fallen by more over the last decade. In the final three months of 2004, 66 per cent of people in Britain listened to BBC network radio every week. Lord Hall also used the BBC Trust meeting to note the strong performance of BBC Radio 6, the digital music station which the Corporation had at one point been planning to scrap. â€˜He reported that the recent RAJAR figures showed that 6Music had become the first digital-only station to reach two million listeners,â€™ the minutes said. Earlier this month, Matthew Postgate, the BBCâ€™s chief technology officer, said the Corporation would adopt a new â€˜digital firstâ€™ strategy, to help it target a new generation of users. He said the organisation needed to â€˜learn lessonsâ€™ if they want to â€˜compete with organisations that were born in the digital ageâ€™. â€˜But he added: â€˜We need to learn lessons from the past. We need to learn lessons from the future. We need to learn lessons from the past. We need to learn lessons from the future. We need to learn lessons from the future. We need to learn lessons from the future. We need to learn lessons from the future. We need to learn lessons from the future. We need to learn lessons from the future. We need to learn lessons from the future. We need to learn lessons from the future. We need to learn lessons from the future. We need to learn lessons from the future. We need to learn lessons from the future. We need to learn lessons from the future. We need to learn lessons from the future. We need to learn lessons from the future. We need to learn lessons from the future. We need to learn lessons from the future. We need to learn lessons from the future. We need to learn lessons from the future. We need to learn lessons from the future. We need to learn lessons from the future. We need to learn lessons from the future. We need to learn lessons from the future. We need to learn lessons from the future. We need to learn lessons from the future. We need to learn lessons from the future. We need to learn lessons from the future. We need to learn lessons from the future. We need to learn lessons from the future. We need to learn lessons from the future. We need to learn lessons from the future. We need to learn lessons from the future. We need to learn lessons from the future. We need to learn lessons from the future. We need to learn lessons from the future. We need to learn lessons from the future. We need to learn lessons from the future. We need to learn lessons from the future. We need to learn lessons from the future. We need to learn lessons from the future. We need to learn lessons from the future. We need to learn lessons from the future. We need to learn lessons from the future. We need to learn lessons from the\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GPT-2 Summary:\n",
            " summarize: (CNN)So, you'd like a \"Full House\" reunion and spinoff? You got it, dude! Co-star John Stamos announced Monday night on \"Jimmy Kimmel Live\" that Netflix has ordered up a reunion special, followed by a spinoff series called \"Fuller House.\" The show will feature Candace Cameron Bure, who played eldest daughter D.J. Tanner in the original series -- which aired from 1987 to 1995 -- as the recently widowed mother of three boys. \"It's sort of a role reversal, and we turn the house over to her,\" Stamos told Kimmel. Jodie Sweetin, who played Stephanie Tanner in the original series, and Andrea Barber, who portrayed D.J.'s best friend Kimmy Gibbler, will both return for the new series, Netflix said. Stamos will produce and guest star. Talks with co-starsBob Saget, Mary-Kate and Ashley Olsen, Dave Coulier and Lori Loughlin are ongoing, Netflix said. The show will be available next year, Netflix said. \"As big fans of the original Full House, we are thrilled to be able to introduce Fuller House's new narrative to existing fans worldwide, who grew up on the original, as well as a new generation of global viewers that have grown up with the Tanners in syndication,\"  Netflix Vice President of Original Content Cindy Holland said in a statement. The show starts with Tanner -- now named Tanner-Fuller (get it... Fuller?) -- pregnant, recently widowed and living in San Francisco. Her younger sister Stephanie -- now an aspiring musician -- and her lifelong best friend and fellow single mom, Kimmy, move in to help her care for her two boys and the new baby. On Monday, Barber tweeted Cameron Bure to ask whether she was ready to resume their onscreen friendship. \"We never stopped,\" Cameron Bure tweeted back. Fans were over the moon at the news. \"Fuller House is a great show, and we're thrilled to be able to bring it back to life for the first time in a long time,\" Cameron Bure said in a statement. \"We're thrilled to be able to bring it back to life for the first time in a long time,\" Cameron Bure tweeted back. Fans were over the moon at the news. \"Fuller House is a great show, and we're thrilled to be able to bring it back to life for the first time in a long time,\" Cameron Bure said in a statement. \"We're thrilled to be able to bring it back to life for the first time in a long time,\" Cameron Bure said in a statement. \"We're thrilled to be able to bring it back to life for the first time in a long time,\" Cameron Bure said in a statement. \"We're thrilled to be able to bring it back to life for the first time in a long time,\" Cameron Bure said in a statement. \"We're thrilled to be able to bring it back to life for the first time in a long time,\" Cameron Bure said in a statement. \"We're thrilled to be able to bring it back to life for the first time in a long time,\" Cameron Bure said in a statement. \"We're thrilled to be able to bring it back to life for the first time in a long time,\" Cameron Bure said in a statement. \"We're thrilled to be able to bring it back to life for the first time in a long time,\" Cameron Bure said in a statement. \"We're thrilled to be able to bring it back to life for the first time in a long time,\" Cameron Bure said in a statement. \"We're thrilled to be able to bring it back to life for the first time in a long time,\" Cameron Bure said in a statement. \"We're thrilled to be able to bring it back to life for the first time in a long time,\" Cameron Bure said in a statement. \"We're thrilled to be able to bring it back to life for the first time in a long time,\" Cameron Bure said in a statement. \"We're thrilled to be able to bring it back to life for the first time in a long time,\" Cameron Bure said in a statement. \"We're thrilled to be able to bring it back to life for the first time in a long time,\" Cameron Bure said in a statement. \"We're thrilled to be able to bring it back to life for the first time in a long time,\" Cameron Bure said in a statement. \"We're thrilled to be able to bring it back to life for the first time in a long time,\" Cameron Bure said in a statement. \"We're thrilled to be able to bring it back to life for the first time in a long time,\" Cameron Bure said in a statement. \"We're thrilled to\n"
          ]
        },
        {
          "ename": "ValueError",
          "evalue": "Input length of input_ids is 1024, but `max_length` is set to 1000. This can lead to unexpected behavior. You should consider increasing `max_length` or, better yet, setting `max_new_tokens`.",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-04b7e12e9944>\u001b[0m in \u001b[0;36m<cell line: 28>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;31m# Call the main function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m \u001b[0mprocess_articles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-19-04b7e12e9944>\u001b[0m in \u001b[0;36mprocess_articles\u001b[0;34m(dataset)\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterrows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0marticle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'article'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0msummary\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_summary_gpt2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marticle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"GPT-2 Summary:\\n\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msummary\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-19-04b7e12e9944>\u001b[0m in \u001b[0;36mgenerate_summary_gpt2\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mgenerate_summary_gpt2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgpt2_tokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"summarize: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_tensors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"pt\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1024\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtruncation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0msummary_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgpt2_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m40\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlength_penalty\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_beams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mearly_stopping\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m     \u001b[0msummary\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgpt2_tokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msummary_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskip_special_tokens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0msummary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/_contextlib.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mctx_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001b[0m\n\u001b[1;32m   1464\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_setup_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcache_cls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_batch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_cache_len\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgeneration_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_length\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1465\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1466\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_generated_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgeneration_config\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_ids_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhas_default_max_length\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1467\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1468\u001b[0m         \u001b[0;31m# 7. determine generation mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py\u001b[0m in \u001b[0;36m_validate_generated_length\u001b[0;34m(self, generation_config, input_ids_length, has_default_max_length)\u001b[0m\n\u001b[1;32m   1184\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minput_ids_length\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mgeneration_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_length\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1185\u001b[0m             \u001b[0minput_ids_string\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"decoder_input_ids\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_encoder_decoder\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"input_ids\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1186\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m   1187\u001b[0m                 \u001b[0;34mf\"Input length of {input_ids_string} is {input_ids_length}, but `max_length` is set to\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1188\u001b[0m                 \u001b[0;34mf\" {generation_config.max_length}. This can lead to unexpected behavior. You should consider\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Input length of input_ids is 1024, but `max_length` is set to 1000. This can lead to unexpected behavior. You should consider increasing `max_length` or, better yet, setting `max_new_tokens`."
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
        "from rouge import Rouge\n",
        "\n",
        "# Load the dataset\n",
        "file_path = \"test.csv\"\n",
        "dataset = pd.read_csv(file_path)\n",
        "\n",
        "# Load GPT-2 model and tokenizer\n",
        "gpt2_tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
        "gpt2_model = GPT2LMHeadModel.from_pretrained('gpt2')\n",
        "\n",
        "# Function for text summarization using GPT-2 model\n",
        "def generate_summary_gpt2(text):\n",
        "    inputs = gpt2_tokenizer.encode(\"summarize: \" + text, return_tensors=\"pt\", max_length=1024, truncation=True)\n",
        "    summary_ids = gpt2_model.generate(inputs, max_length=1000, min_length=40, length_penalty=2.0, num_beams=4, early_stopping=True)\n",
        "    summary = gpt2_tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
        "    return summary\n",
        "\n",
        "# Main function to process each article in the dataset\n",
        "def process_articles(dataset):\n",
        "    for index, row in dataset.iterrows():\n",
        "        article = row['article']\n",
        "        summary = generate_summary_gpt2(article)\n",
        "        print(\"GPT-2 Summary:\\n\", summary)\n",
        "\n",
        "# Call the main function\n",
        "process_articles(dataset)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "039fb807ac6b49269fdab8c32b607aa0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0433cb7e967a4e45960ac5a7af6ded73": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0466b74024004c05aca1ab4f61b077f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "06ea068b54d549eb954a942eb764748e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "075a8d1e7cc848ac96cda9f6ca146529": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0890a6f7a7a342f5abfdd8e4f1d9eea6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "090fc670cebd4e858c3560e6cb1263e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "12c028302e894a728e848409e4051fde": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1335deb08d524996b4f66836473c8f52": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1703b546d3954e63ac1a8161e19e7f81": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_bd7c730edb574efeb00a3cd3db378fd9",
              "IPY_MODEL_d2de7ffbe6a34268829b2e4f890e9537",
              "IPY_MODEL_8cbba3cdb9d8438e872e243148f181a3"
            ],
            "layout": "IPY_MODEL_d172034ce6914023bed2cfee54c52aad"
          }
        },
        "19e02c007fc247728fbb20085b217e13": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2079401f23724393ad181d6c5c689dfa": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_98c458f661c940ca8bbe389b6712b204",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_70803203a6eb412690b761113f836add",
            "value": "â€‡456k/456kâ€‡[00:00&lt;00:00,â€‡22.4MB/s]"
          }
        },
        "2cf45b705ae84a3fa56f1ba62c4e2f99": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_efe4c577478449f4805c9c58a0f34c0d",
              "IPY_MODEL_e10a2e4aff3147f99dfa288add2469dd",
              "IPY_MODEL_bde8c243711d45e2b8065582f20ce72f"
            ],
            "layout": "IPY_MODEL_19e02c007fc247728fbb20085b217e13"
          }
        },
        "2d3935dc021c4dda9347bf1cebc57b62": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2da5f54840cf4a4aa3d19eade319cf67": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3231d6bafa5a43f8a2f86e3e6aa4a0fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dcbc09b26b1847eaac54215b77fcb5c4",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_06ea068b54d549eb954a942eb764748e",
            "value": "â€‡1.80k/1.80kâ€‡[00:00&lt;00:00,â€‡91.8kB/s]"
          }
        },
        "3899c929344d49929b40704c8685423a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "40ddf450b8694ba38c723553e82b7677": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4713d0cd52d24df2a57553a7acce03cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4e1571f445144bc19f163879434de4e8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "51f9c15d44674724a03774652a831627": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a653d99d42af4420af9581825b8d5a07",
              "IPY_MODEL_85e9fee68f704c94b94e535090d86868",
              "IPY_MODEL_2079401f23724393ad181d6c5c689dfa"
            ],
            "layout": "IPY_MODEL_039fb807ac6b49269fdab8c32b607aa0"
          }
        },
        "57ac8bdfda904af19bd74e09214d7e8b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5a123fea44464a1a837ee5ce5d0e0bf6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9b8ba72693774eeb8be28cbb831f2790",
            "max": 26,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_86b8d9d8e55645218b1e1a19ba8fd494",
            "value": 26
          }
        },
        "5c70383ce36c4bf0abe490f698ff1d4b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5d940137e45f42a5b15b0e96fe55462f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5f8dc93910724537954edb8ad977ecef": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6a53a39f48944be1a9438981a2997c56": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2d3935dc021c4dda9347bf1cebc57b62",
            "max": 1802,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_075a8d1e7cc848ac96cda9f6ca146529",
            "value": 1802
          }
        },
        "70803203a6eb412690b761113f836add": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "73724debb8024d80ae6dcefc3fb881de": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "85e9fee68f704c94b94e535090d86868": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_40ddf450b8694ba38c723553e82b7677",
            "max": 456318,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8625b0947b834383b5618f6919829492",
            "value": 456318
          }
        },
        "8625b0947b834383b5618f6919829492": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "86b8d9d8e55645218b1e1a19ba8fd494": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8c9a9a66ce764e8784c381ed23b3a8a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a7834e638b8d498587e8fbd3375b3f41",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_0466b74024004c05aca1ab4f61b077f5",
            "value": "config.json:â€‡100%"
          }
        },
        "8cbba3cdb9d8438e872e243148f181a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ac03819eab614f1eb81587245b62e1d7",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_f8c6844bdd1e482385737021500a4508",
            "value": "â€‡1.22G/1.22Gâ€‡[00:43&lt;00:00,â€‡48.8MB/s]"
          }
        },
        "98c458f661c940ca8bbe389b6712b204": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9b8ba72693774eeb8be28cbb831f2790": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a653d99d42af4420af9581825b8d5a07": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_aaec799a6984498c83999193f6d6aaa9",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_5f8dc93910724537954edb8ad977ecef",
            "value": "merges.txt:â€‡100%"
          }
        },
        "a7834e638b8d498587e8fbd3375b3f41": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aaec799a6984498c83999193f6d6aaa9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ac03819eab614f1eb81587245b62e1d7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b62b98fc82fc4206b0b12c48ca5f0cb5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8c9a9a66ce764e8784c381ed23b3a8a7",
              "IPY_MODEL_6a53a39f48944be1a9438981a2997c56",
              "IPY_MODEL_3231d6bafa5a43f8a2f86e3e6aa4a0fd"
            ],
            "layout": "IPY_MODEL_1335deb08d524996b4f66836473c8f52"
          }
        },
        "bd7c730edb574efeb00a3cd3db378fd9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0890a6f7a7a342f5abfdd8e4f1d9eea6",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_090fc670cebd4e858c3560e6cb1263e6",
            "value": "pytorch_model.bin:â€‡100%"
          }
        },
        "bde8c243711d45e2b8065582f20ce72f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2da5f54840cf4a4aa3d19eade319cf67",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_0433cb7e967a4e45960ac5a7af6ded73",
            "value": "â€‡899k/899kâ€‡[00:00&lt;00:00,â€‡28.5MB/s]"
          }
        },
        "bf2f2bc6fa8b49709bd05c23d3fc0659": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c6db81e5d6574ffb8613e51003077c73": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5d940137e45f42a5b15b0e96fe55462f",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_12c028302e894a728e848409e4051fde",
            "value": "â€‡26.0/26.0â€‡[00:00&lt;00:00,â€‡1.68kB/s]"
          }
        },
        "ca895eb1ef254a76877adb28d5b37d50": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5c70383ce36c4bf0abe490f698ff1d4b",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_4713d0cd52d24df2a57553a7acce03cf",
            "value": "tokenizer_config.json:â€‡100%"
          }
        },
        "cf04f57fcac64daa89df0cd43668f6ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ca895eb1ef254a76877adb28d5b37d50",
              "IPY_MODEL_5a123fea44464a1a837ee5ce5d0e0bf6",
              "IPY_MODEL_c6db81e5d6574ffb8613e51003077c73"
            ],
            "layout": "IPY_MODEL_73724debb8024d80ae6dcefc3fb881de"
          }
        },
        "d172034ce6914023bed2cfee54c52aad": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d2de7ffbe6a34268829b2e4f890e9537": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e73d2dd712714f09b3d68fac3bc7ceb0",
            "max": 1222317369,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_57ac8bdfda904af19bd74e09214d7e8b",
            "value": 1222317369
          }
        },
        "dcbc09b26b1847eaac54215b77fcb5c4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e10a2e4aff3147f99dfa288add2469dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bf2f2bc6fa8b49709bd05c23d3fc0659",
            "max": 898822,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_fcf9bec909094cdfb2d59ae7a46f205e",
            "value": 898822
          }
        },
        "e73d2dd712714f09b3d68fac3bc7ceb0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "efe4c577478449f4805c9c58a0f34c0d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4e1571f445144bc19f163879434de4e8",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_3899c929344d49929b40704c8685423a",
            "value": "vocab.json:â€‡100%"
          }
        },
        "f8c6844bdd1e482385737021500a4508": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fcf9bec909094cdfb2d59ae7a46f205e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}